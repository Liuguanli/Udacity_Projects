{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Image Classification\n",
    "In this project, you'll classify images from the [CIFAR-10 dataset](https://www.cs.toronto.edu/~kriz/cifar.html).  The dataset consists of airplanes, dogs, cats, and other objects. You'll preprocess the images, then train a convolutional neural network on all the samples. The images need to be normalized and the labels need to be one-hot encoded.  You'll get to apply what you learned and build a convolutional, max pooling, dropout, and fully connected layers.  At the end, you'll get to see your neural network's predictions on the sample images.\n",
    "## Get the Data\n",
    "Run the following cell to download the [CIFAR-10 dataset for python](https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All files found!\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "from urllib.request import urlretrieve\n",
    "from os.path import isfile, isdir\n",
    "from tqdm import tqdm\n",
    "import problem_unittests as tests\n",
    "import tarfile\n",
    "\n",
    "cifar10_dataset_folder_path = 'cifar-10-batches-py'\n",
    "\n",
    "# Use Floyd's cifar-10 dataset if present\n",
    "floyd_cifar10_location = '/cifar/cifar-10-python.tar.gz'\n",
    "if isfile(floyd_cifar10_location):\n",
    "    tar_gz_path = floyd_cifar10_location\n",
    "else:\n",
    "    tar_gz_path = 'cifar-10-python.tar.gz'\n",
    "\n",
    "class DLProgress(tqdm):\n",
    "    last_block = 0\n",
    "\n",
    "    def hook(self, block_num=1, block_size=1, total_size=None):\n",
    "        self.total = total_size\n",
    "        self.update((block_num - self.last_block) * block_size)\n",
    "        self.last_block = block_num\n",
    "\n",
    "if not isfile(tar_gz_path):\n",
    "    with DLProgress(unit='B', unit_scale=True, miniters=1, desc='CIFAR-10 Dataset') as pbar:\n",
    "        urlretrieve(\n",
    "            'https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz',\n",
    "            tar_gz_path,\n",
    "            pbar.hook)\n",
    "\n",
    "if not isdir(cifar10_dataset_folder_path):\n",
    "    with tarfile.open(tar_gz_path) as tar:\n",
    "        tar.extractall()\n",
    "        tar.close()\n",
    "\n",
    "\n",
    "tests.test_folder_path(cifar10_dataset_folder_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore the Data\n",
    "The dataset is broken into batches to prevent your machine from running out of memory.  The CIFAR-10 dataset consists of 5 batches, named `data_batch_1`, `data_batch_2`, etc.. Each batch contains the labels and images that are one of the following:\n",
    "* airplane\n",
    "* automobile\n",
    "* bird\n",
    "* cat\n",
    "* deer\n",
    "* dog\n",
    "* frog\n",
    "* horse\n",
    "* ship\n",
    "* truck\n",
    "\n",
    "Understanding a dataset is part of making predictions on the data.  Play around with the code cell below by changing the `batch_id` and `sample_id`. The `batch_id` is the id for a batch (1-5). The `sample_id` is the id for a image and label pair in the batch.\n",
    "\n",
    "Ask yourself \"What are all possible labels?\", \"What is the range of values for the image data?\", \"Are the labels in order or random?\".  Answers to questions like these will help you preprocess the data and end up with better predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Stats of batch 1:\n",
      "Samples: 10000\n",
      "Label Counts: {0: 1005, 1: 974, 2: 1032, 3: 1016, 4: 999, 5: 937, 6: 1030, 7: 1001, 8: 1025, 9: 981}\n",
      "First 20 Labels: [6, 9, 9, 4, 1, 1, 2, 7, 8, 3, 4, 7, 7, 2, 9, 9, 9, 3, 2, 6]\n",
      "\n",
      "Example of Image 5:\n",
      "Image - Min Value: 0 Max Value: 252\n",
      "Image - Shape: (32, 32, 3)\n",
      "Label - Label Id: 1 Name: automobile\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x164925930b8>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 250,
       "width": 253
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "import helper\n",
    "import numpy as np\n",
    "\n",
    "# Explore the dataset\n",
    "batch_id = 1\n",
    "sample_id = 5\n",
    "helper.display_stats(cifar10_dataset_folder_path, batch_id, sample_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implement Preprocess Functions\n",
    "### Normalize\n",
    "In the cell below, implement the `normalize` function to take in image data, `x`, and return it as a normalized Numpy array. The values should be in the range of 0 to 1, inclusive.  The return object should be the same shape as `x`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def normalize(x):\n",
    "    \"\"\"\n",
    "    Normalize a list of sample image data in the range of 0 to 1\n",
    "    : x: List of image data.  The image shape is (32, 32, 3)\n",
    "    : return: Numpy array of normalize data\n",
    "    \"\"\"\n",
    "    nmin = np.amin(x)\n",
    "    nmax = np.amax(x)\n",
    "    # TODO: Implement Function\n",
    "    return (x - nmin)/(nmax - nmin)\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_normalize(normalize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One-hot encode\n",
    "Just like the previous code cell, you'll be implementing a function for preprocessing.  This time, you'll implement the `one_hot_encode` function. The input, `x`, are a list of labels.  Implement the function to return the list of labels as One-Hot encoded Numpy array.  The possible values for labels are 0 to 9. The one-hot encoding function should return the same encoding for each value between each call to `one_hot_encode`.  Make sure to save the map of encodings outside the function.\n",
    "\n",
    "Hint: Don't reinvent the wheel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def one_hot_encode(x):\n",
    "    \"\"\"\n",
    "    One hot encode a list of sample labels. Return a one-hot encoded vector for each label.\n",
    "    : x: List of sample Labels\n",
    "    : return: Numpy array of one-hot encoded labels\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "        \n",
    "    y = np.zeros((len(x), 10))\n",
    "    for i in range(len(x)):\n",
    "        y[i,x[i]] = 1\n",
    "    return y\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_one_hot_encode(one_hot_encode)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Randomize Data\n",
    "As you saw from exploring the data above, the order of the samples are randomized.  It doesn't hurt to randomize it again, but you don't need to for this dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess all the data and save it\n",
    "Running the code cell below will preprocess all the CIFAR-10 data and save it to file. The code below also uses 10% of the training data for validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "# Preprocess Training, Validation, and Testing Data\n",
    "helper.preprocess_and_save_data(cifar10_dataset_folder_path, normalize, one_hot_encode)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check Point\n",
    "This is your first checkpoint.  If you ever decide to come back to this notebook or have to restart the notebook, you can start from here.  The preprocessed data has been saved to disk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "import pickle\n",
    "import problem_unittests as tests\n",
    "import helper\n",
    "\n",
    "# Load the Preprocessed Validation data\n",
    "valid_features, valid_labels = pickle.load(open('preprocess_validation.p', mode='rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the network\n",
    "For the neural network, you'll build each layer into a function.  Most of the code you've seen has been outside of functions. To test your code more thoroughly, we require that you put each layer in a function.  This allows us to give you better feedback and test for simple mistakes using our unittests before you submit your project.\n",
    "\n",
    ">**Note:** If you're finding it hard to dedicate enough time for this course each week, we've provided a small shortcut to this part of the project. In the next couple of problems, you'll have the option to use classes from the [TensorFlow Layers](https://www.tensorflow.org/api_docs/python/tf/layers) or [TensorFlow Layers (contrib)](https://www.tensorflow.org/api_guides/python/contrib.layers) packages to build each layer, except the layers you build in the \"Convolutional and Max Pooling Layer\" section.  TF Layers is similar to Keras's and TFLearn's abstraction to layers, so it's easy to pickup.\n",
    "\n",
    ">However, if you would like to get the most out of this course, try to solve all the problems _without_ using anything from the TF Layers packages. You **can** still use classes from other packages that happen to have the same name as ones you find in TF Layers! For example, instead of using the TF Layers version of the `conv2d` class, [tf.layers.conv2d](https://www.tensorflow.org/api_docs/python/tf/layers/conv2d), you would want to use the TF Neural Network version of `conv2d`, [tf.nn.conv2d](https://www.tensorflow.org/api_docs/python/tf/nn/conv2d). \n",
    "\n",
    "Let's begin!\n",
    "\n",
    "### Input\n",
    "The neural network needs to read the image data, one-hot encoded labels, and dropout keep probability. Implement the following functions\n",
    "* Implement `neural_net_image_input`\n",
    " * Return a [TF Placeholder](https://www.tensorflow.org/api_docs/python/tf/placeholder)\n",
    " * Set the shape using `image_shape` with batch size set to `None`.\n",
    " * Name the TensorFlow placeholder \"x\" using the TensorFlow `name` parameter in the [TF Placeholder](https://www.tensorflow.org/api_docs/python/tf/placeholder).\n",
    "* Implement `neural_net_label_input`\n",
    " * Return a [TF Placeholder](https://www.tensorflow.org/api_docs/python/tf/placeholder)\n",
    " * Set the shape using `n_classes` with batch size set to `None`.\n",
    " * Name the TensorFlow placeholder \"y\" using the TensorFlow `name` parameter in the [TF Placeholder](https://www.tensorflow.org/api_docs/python/tf/placeholder).\n",
    "* Implement `neural_net_keep_prob_input`\n",
    " * Return a [TF Placeholder](https://www.tensorflow.org/api_docs/python/tf/placeholder) for dropout keep probability.\n",
    " * Name the TensorFlow placeholder \"keep_prob\" using the TensorFlow `name` parameter in the [TF Placeholder](https://www.tensorflow.org/api_docs/python/tf/placeholder).\n",
    "\n",
    "These names will be used at the end of the project to load your saved model.\n",
    "\n",
    "Note: `None` for shapes in TensorFlow allow for a dynamic size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image Input Tests Passed.\n",
      "Label Input Tests Passed.\n",
      "Keep Prob Tests Passed.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "def neural_net_image_input(image_shape):\n",
    "    \"\"\"\n",
    "    Return a Tensor for a batch of image input\n",
    "    : image_shape: Shape of the images\n",
    "    : return: Tensor for image input.\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    return tf.placeholder(tf.float32,[None] + list(image_shape),'x')\n",
    "\n",
    "\n",
    "def neural_net_label_input(n_classes):\n",
    "    \"\"\"\n",
    "    Return a Tensor for a batch of label input\n",
    "    : n_classes: Number of classes\n",
    "    : return: Tensor for label input.\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    return tf.placeholder(tf.int32,[None, n_classes],'y')\n",
    "\n",
    "\n",
    "def neural_net_keep_prob_input():\n",
    "    \"\"\"\n",
    "    Return a Tensor for keep probability\n",
    "    : return: Tensor for keep probability.\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    return tf.placeholder(tf.float32, None, 'keep_prob')\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tf.reset_default_graph()\n",
    "tests.test_nn_image_inputs(neural_net_image_input)\n",
    "tests.test_nn_label_inputs(neural_net_label_input)\n",
    "tests.test_nn_keep_prob_inputs(neural_net_keep_prob_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convolution and Max Pooling Layer\n",
    "Convolution layers have a lot of success with images. For this code cell, you should implement the function `conv2d_maxpool` to apply convolution then max pooling:\n",
    "* Create the weight and bias using `conv_ksize`, `conv_num_outputs` and the shape of `x_tensor`.\n",
    "* Apply a convolution to `x_tensor` using weight and `conv_strides`.\n",
    " * We recommend you use same padding, but you're welcome to use any padding.\n",
    "* Add bias\n",
    "* Add a nonlinear activation to the convolution.\n",
    "* Apply Max Pooling using `pool_ksize` and `pool_strides`.\n",
    " * We recommend you use same padding, but you're welcome to use any padding.\n",
    "\n",
    "**Note:** You **can't** use [TensorFlow Layers](https://www.tensorflow.org/api_docs/python/tf/layers) or [TensorFlow Layers (contrib)](https://www.tensorflow.org/api_guides/python/contrib.layers) for **this** layer, but you can still use TensorFlow's [Neural Network](https://www.tensorflow.org/api_docs/python/tf/nn) package. You may still use the shortcut option for all the **other** layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def conv2d_maxpool(x_tensor, conv_num_outputs, conv_ksize, conv_strides, pool_ksize, pool_strides):\n",
    "    \"\"\"\n",
    "    Apply convolution then max pooling to x_tensor\n",
    "    :param x_tensor: TensorFlow Tensor\n",
    "    :param conv_num_outputs: Number of outputs for the convolutional layer\n",
    "    :param conv_ksize: kernal size 2-D Tuple for the convolutional layer\n",
    "    :param conv_strides: Stride 2-D Tuple for convolution\n",
    "    :param pool_ksize: kernal size 2-D Tuple for pool\n",
    "    :param pool_strides: Stride 2-D Tuple for pool\n",
    "    : return: A tensor that represents convolution and max pooling of x_tensor\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    \n",
    "    channels = x_tensor.get_shape().as_list()[-1]\n",
    "    padding = 'SAME'\n",
    "    weight = tf.Variable(tf.truncated_normal(([conv_ksize[0], conv_ksize[1], channels, conv_num_outputs]), 0, 0.1))\n",
    "    biases = tf.Variable(tf.zeros(conv_num_outputs))\n",
    "    output = tf.nn.conv2d(x_tensor, weight, [1, conv_strides[0], conv_strides[1], 1], padding)\n",
    "    output = tf.nn.bias_add(output, biases)\n",
    "    output = tf.nn.relu(output)\n",
    "    output = tf.nn.max_pool(output, [1, pool_ksize[0], pool_ksize[1], 1], [1, pool_strides[0], pool_strides[1], 1], padding)\n",
    "    return output \n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_con_pool(conv2d_maxpool)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Flatten Layer\n",
    "Implement the `flatten` function to change the dimension of `x_tensor` from a 4-D tensor to a 2-D tensor.  The output should be the shape (*Batch Size*, *Flattened Image Size*). Shortcut option: you can use classes from the [TensorFlow Layers](https://www.tensorflow.org/api_docs/python/tf/layers) or [TensorFlow Layers (contrib)](https://www.tensorflow.org/api_guides/python/contrib.layers) packages for this layer. For more of a challenge, only use other TensorFlow packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def flatten(x_tensor):\n",
    "    \"\"\"\n",
    "    Flatten x_tensor to (Batch Size, Flattened Image Size)\n",
    "    : x_tensor: A tensor of size (Batch Size, ...), where ... are the image dimensions.\n",
    "    : return: A tensor of size (Batch Size, Flattened Image Size).\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    flattened_image_size = np.prod(x_tensor.get_shape().as_list()[1:])\n",
    "    return tf.reshape(x_tensor, [-1, flattened_image_size])\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_flatten(flatten)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fully-Connected Layer\n",
    "Implement the `fully_conn` function to apply a fully connected layer to `x_tensor` with the shape (*Batch Size*, *num_outputs*). Shortcut option: you can use classes from the [TensorFlow Layers](https://www.tensorflow.org/api_docs/python/tf/layers) or [TensorFlow Layers (contrib)](https://www.tensorflow.org/api_guides/python/contrib.layers) packages for this layer. For more of a challenge, only use other TensorFlow packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def fully_conn(x_tensor, num_outputs):\n",
    "    \"\"\"\n",
    "    Apply a fully connected layer to x_tensor using weight and bias\n",
    "    : x_tensor: A 2-D tensor where the first dimension is batch size.\n",
    "    : num_outputs: The number of output that the new tensor should be.\n",
    "    : return: A 2-D tensor where the second dimension is num_outputs.\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    weights = tf.Variable(tf.truncated_normal([x_tensor.get_shape().as_list()[1], num_outputs], 0, 0.1))\n",
    "    biases = tf.Variable(tf.zeros(num_outputs))\n",
    "    return tf.nn.relu(tf.add(tf.matmul(x_tensor, weights), biases))\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_fully_conn(fully_conn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Output Layer\n",
    "Implement the `output` function to apply a fully connected layer to `x_tensor` with the shape (*Batch Size*, *num_outputs*). Shortcut option: you can use classes from the [TensorFlow Layers](https://www.tensorflow.org/api_docs/python/tf/layers) or [TensorFlow Layers (contrib)](https://www.tensorflow.org/api_guides/python/contrib.layers) packages for this layer. For more of a challenge, only use other TensorFlow packages.\n",
    "\n",
    "**Note:** Activation, softmax, or cross entropy should **not** be applied to this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def output(x_tensor, num_outputs):\n",
    "    \"\"\"\n",
    "    Apply a output layer to x_tensor using weight and bias\n",
    "    : x_tensor: A 2-D tensor where the first dimension is batch size.\n",
    "    : num_outputs: The number of output that the new tensor should be.\n",
    "    : return: A 2-D tensor where the second dimension is num_outputs.\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    weights = tf.Variable(tf.truncated_normal([x_tensor.get_shape().as_list()[1], num_outputs], 0, 0.1))\n",
    "    biases = tf.Variable(tf.zeros(num_outputs))\n",
    "    return tf.add(tf.matmul(x_tensor, weights), biases)\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_output(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Convolutional Model\n",
    "Implement the function `conv_net` to create a convolutional neural network model. The function takes in a batch of images, `x`, and outputs logits.  Use the layers you created above to create this model:\n",
    "\n",
    "* Apply 1, 2, or 3 Convolution and Max Pool layers\n",
    "* Apply a Flatten Layer\n",
    "* Apply 1, 2, or 3 Fully Connected Layers\n",
    "* Apply an Output Layer\n",
    "* Return the output\n",
    "* Apply [TensorFlow's Dropout](https://www.tensorflow.org/api_docs/python/tf/nn/dropout) to one or more layers in the model using `keep_prob`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def train_neural_network(session, optimizer, keep_probability, feature_batch, label_batch):\n",
    "    \"\"\"\n",
    "    Optimize the session on a batch of images and labels\n",
    "    : session: Current TensorFlow session\n",
    "    : optimizer: TensorFlow optimizer function\n",
    "    : keep_probability: keep probability\n",
    "    : feature_batch: Batch of Numpy image data\n",
    "    : label_batch: Batch of Numpy label data\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    session.run(optimizer, feed_dict={x: feature_batch, y: label_batch, keep_prob:keep_probability})\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_train_nn(train_neural_network)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neural Network Built!\n"
     ]
    }
   ],
   "source": [
    "def conv_net(x, keep_prob):\n",
    "    \"\"\"\n",
    "    Create a convolutional neural network model\n",
    "    : x: Placeholder tensor that holds image data.\n",
    "    : keep_prob: Placeholder tensor that hold dropout keep probability.\n",
    "    : return: Tensor that represents logits\n",
    "    \"\"\"\n",
    "    # TODO: Apply 1, 2, or 3 Convolution and Max Pool layers\n",
    "    #    Play around with different number of outputs, kernel size and stride\n",
    "    # Function Definition from Above:\n",
    "    #    conv2d_maxpool(x_tensor, conv_num_outputs, conv_ksize, conv_strides, pool_ksize, pool_strides)\n",
    "    \n",
    "    output1 = conv2d_maxpool(x, 20, (2,2),(1,1),(4,4),(1,1))\n",
    "    output1 = tf.nn.dropout(output1, keep_prob)\n",
    "\n",
    "\n",
    "    # TODO: Apply a Flatten Layer\n",
    "    # Function Definition from Above:\n",
    "    #   flatten(x_tensor)\n",
    "    \n",
    "    output2 = flatten(output1)\n",
    "    \n",
    "\n",
    "    # TODO: Apply 1, 2, or 3 Fully Connected Layers\n",
    "    #    Play around with different number of outputs\n",
    "    # Function Definition from Above:\n",
    "    #   fully_conn(x_tensor, num_outputs)\n",
    "    \n",
    "    output3 = fully_conn(output2, 200)\n",
    "    output3 = tf.nn.dropout(output3, keep_prob)\n",
    "    \n",
    "    \n",
    "    # TODO: Apply an Output Layer\n",
    "    #    Set this to the number of classes\n",
    "    # Function Definition from Above:\n",
    "    #   output(x_tensor, num_outputs)\n",
    "    \n",
    "    output4 = output(output3, 10)\n",
    "    # TODO: return output\n",
    "    return output4\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "\n",
    "##############################\n",
    "## Build the Neural Network ##\n",
    "##############################\n",
    "\n",
    "# Remove previous weights, bias, inputs, etc..\n",
    "tf.reset_default_graph()\n",
    "\n",
    "# Inputs\n",
    "x = neural_net_image_input((32, 32, 3))\n",
    "y = neural_net_label_input(10)\n",
    "keep_prob = neural_net_keep_prob_input()\n",
    "\n",
    "# Model\n",
    "logits = conv_net(x, keep_prob)\n",
    "\n",
    "# Name logits Tensor, so that is can be loaded from disk after training\n",
    "logits = tf.identity(logits, name='logits')\n",
    "\n",
    "# Loss and Optimizer\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=y))\n",
    "optimizer = tf.train.AdamOptimizer().minimize(cost)\n",
    "\n",
    "# Accuracy\n",
    "correct_pred = tf.equal(tf.argmax(logits, 1), tf.argmax(y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32), name='accuracy')\n",
    "\n",
    "tests.test_conv_net(conv_net)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the Neural Network\n",
    "### Single Optimization\n",
    "Implement the function `train_neural_network` to do a single optimization.  The optimization should use `optimizer` to optimize in `session` with a `feed_dict` of the following:\n",
    "* `x` for image input\n",
    "* `y` for labels\n",
    "* `keep_prob` for keep probability for dropout\n",
    "\n",
    "This function will be called for each batch, so `tf.global_variables_initializer()` has already been called.\n",
    "\n",
    "Note: Nothing needs to be returned. This function is only optimizing the neural network."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show Stats\n",
    "Implement the function `print_stats` to print loss and validation accuracy.  Use the global variables `valid_features` and `valid_labels` to calculate validation accuracy.  Use a keep probability of `1.0` to calculate the loss and validation accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_stats(session, feature_batch, label_batch, cost, accuracy):\n",
    "    \"\"\"\n",
    "    Print information about loss and validation accuracy\n",
    "    : session: Current TensorFlow session\n",
    "    : feature_batch: Batch of Numpy image data\n",
    "    : label_batch: Batch of Numpy label data\n",
    "    : cost: TensorFlow cost function\n",
    "    : accuracy: TensorFlow accuracy function\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    loss = session.run(cost, feed_dict={x: feature_batch, y:label_batch, keep_prob:1})\n",
    "    valid_accuracy = sess.run(accuracy, feed_dict={x: valid_features, y: valid_labels, keep_prob:1})\n",
    "    \n",
    "    print('Loss: {:^10.4f} Validation Accuracy: {:.6f}'.format(loss, valid_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameters\n",
    "Tune the following parameters:\n",
    "* Set `epochs` to the number of iterations until the network stops learning or start overfitting\n",
    "* Set `batch_size` to the highest number that your machine has memory for.  Most people set them to common sizes of memory:\n",
    " * 64\n",
    " * 128\n",
    " * 256\n",
    " * ...\n",
    "* Set `keep_probability` to the probability of keeping a node using dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Tune Parameters\n",
    "epochs = 100\n",
    "batch_size = 512\n",
    "keep_probability = 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train on a Single CIFAR-10 Batch\n",
    "Instead of training the neural network on all the CIFAR-10 batches of data, let's use a single batch. This should save time while you iterate on the model to get a better accuracy.  Once the final validation accuracy is 50% or greater, run the model on all the data in the next section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking the Training on a Single Batch...\n",
      "Epoch  1, CIFAR-10 Batch 1:  Loss:   2.2482   Validation Accuracy: 0.183200\n",
      "Epoch  2, CIFAR-10 Batch 1:  Loss:   2.1384   Validation Accuracy: 0.234600\n",
      "Epoch  3, CIFAR-10 Batch 1:  Loss:   2.0302   Validation Accuracy: 0.270200\n",
      "Epoch  4, CIFAR-10 Batch 1:  Loss:   1.9765   Validation Accuracy: 0.311800\n",
      "Epoch  5, CIFAR-10 Batch 1:  Loss:   1.8918   Validation Accuracy: 0.343800\n",
      "Epoch  6, CIFAR-10 Batch 1:  Loss:   1.8185   Validation Accuracy: 0.380800\n",
      "Epoch  7, CIFAR-10 Batch 1:  Loss:   1.7364   Validation Accuracy: 0.410000\n",
      "Epoch  8, CIFAR-10 Batch 1:  Loss:   1.6675   Validation Accuracy: 0.433800\n",
      "Epoch  9, CIFAR-10 Batch 1:  Loss:   1.6128   Validation Accuracy: 0.450200\n",
      "Epoch 10, CIFAR-10 Batch 1:  Loss:   1.5376   Validation Accuracy: 0.461000\n",
      "Epoch 11, CIFAR-10 Batch 1:  Loss:   1.4997   Validation Accuracy: 0.472800\n",
      "Epoch 12, CIFAR-10 Batch 1:  Loss:   1.4385   Validation Accuracy: 0.489200\n",
      "Epoch 13, CIFAR-10 Batch 1:  Loss:   1.3847   Validation Accuracy: 0.503400\n",
      "Epoch 14, CIFAR-10 Batch 1:  Loss:   1.3581   Validation Accuracy: 0.521800\n",
      "Epoch 15, CIFAR-10 Batch 1:  Loss:   1.3118   Validation Accuracy: 0.515200\n",
      "Epoch 16, CIFAR-10 Batch 1:  Loss:   1.2831   Validation Accuracy: 0.522200\n",
      "Epoch 17, CIFAR-10 Batch 1:  Loss:   1.2337   Validation Accuracy: 0.533800\n",
      "Epoch 18, CIFAR-10 Batch 1:  Loss:   1.2092   Validation Accuracy: 0.535000\n",
      "Epoch 19, CIFAR-10 Batch 1:  Loss:   1.1808   Validation Accuracy: 0.543400\n",
      "Epoch 20, CIFAR-10 Batch 1:  Loss:   1.1466   Validation Accuracy: 0.543200\n",
      "Epoch 21, CIFAR-10 Batch 1:  Loss:   1.1252   Validation Accuracy: 0.548000\n",
      "Epoch 22, CIFAR-10 Batch 1:  Loss:   1.1029   Validation Accuracy: 0.550000\n",
      "Epoch 23, CIFAR-10 Batch 1:  Loss:   1.0719   Validation Accuracy: 0.555800\n",
      "Epoch 24, CIFAR-10 Batch 1:  Loss:   1.0578   Validation Accuracy: 0.554800\n",
      "Epoch 25, CIFAR-10 Batch 1:  Loss:   1.0237   Validation Accuracy: 0.558200\n",
      "Epoch 26, CIFAR-10 Batch 1:  Loss:   0.9912   Validation Accuracy: 0.562800\n",
      "Epoch 27, CIFAR-10 Batch 1:  Loss:   0.9760   Validation Accuracy: 0.567000\n",
      "Epoch 28, CIFAR-10 Batch 1:  Loss:   0.9442   Validation Accuracy: 0.564200\n",
      "Epoch 29, CIFAR-10 Batch 1:  Loss:   0.9464   Validation Accuracy: 0.563200\n",
      "Epoch 30, CIFAR-10 Batch 1:  Loss:   0.9137   Validation Accuracy: 0.562800\n",
      "Epoch 31, CIFAR-10 Batch 1:  Loss:   0.8926   Validation Accuracy: 0.571200\n",
      "Epoch 32, CIFAR-10 Batch 1:  Loss:   0.8817   Validation Accuracy: 0.572600\n",
      "Epoch 33, CIFAR-10 Batch 1:  Loss:   0.8649   Validation Accuracy: 0.574400\n",
      "Epoch 34, CIFAR-10 Batch 1:  Loss:   0.8601   Validation Accuracy: 0.561800\n",
      "Epoch 35, CIFAR-10 Batch 1:  Loss:   0.8251   Validation Accuracy: 0.568600\n",
      "Epoch 36, CIFAR-10 Batch 1:  Loss:   0.8074   Validation Accuracy: 0.578200\n",
      "Epoch 37, CIFAR-10 Batch 1:  Loss:   0.8097   Validation Accuracy: 0.579000\n",
      "Epoch 38, CIFAR-10 Batch 1:  Loss:   0.7750   Validation Accuracy: 0.580600\n",
      "Epoch 39, CIFAR-10 Batch 1:  Loss:   0.7664   Validation Accuracy: 0.579200\n",
      "Epoch 40, CIFAR-10 Batch 1:  Loss:   0.7361   Validation Accuracy: 0.582200\n",
      "Epoch 41, CIFAR-10 Batch 1:  Loss:   0.7340   Validation Accuracy: 0.581400\n",
      "Epoch 42, CIFAR-10 Batch 1:  Loss:   0.7067   Validation Accuracy: 0.578800\n",
      "Epoch 43, CIFAR-10 Batch 1:  Loss:   0.6985   Validation Accuracy: 0.587400\n",
      "Epoch 44, CIFAR-10 Batch 1:  Loss:   0.6969   Validation Accuracy: 0.577200\n",
      "Epoch 45, CIFAR-10 Batch 1:  Loss:   0.6842   Validation Accuracy: 0.583200\n",
      "Epoch 46, CIFAR-10 Batch 1:  Loss:   0.6816   Validation Accuracy: 0.583400\n",
      "Epoch 47, CIFAR-10 Batch 1:  Loss:   0.6520   Validation Accuracy: 0.587200\n",
      "Epoch 48, CIFAR-10 Batch 1:  Loss:   0.6282   Validation Accuracy: 0.588000\n",
      "Epoch 49, CIFAR-10 Batch 1:  Loss:   0.6327   Validation Accuracy: 0.587200\n",
      "Epoch 50, CIFAR-10 Batch 1:  Loss:   0.6396   Validation Accuracy: 0.587400\n",
      "Epoch 51, CIFAR-10 Batch 1:  Loss:   0.6160   Validation Accuracy: 0.590400\n",
      "Epoch 52, CIFAR-10 Batch 1:  Loss:   0.6013   Validation Accuracy: 0.591800\n",
      "Epoch 53, CIFAR-10 Batch 1:  Loss:   0.5747   Validation Accuracy: 0.589000\n",
      "Epoch 54, CIFAR-10 Batch 1:  Loss:   0.5847   Validation Accuracy: 0.587800\n",
      "Epoch 55, CIFAR-10 Batch 1:  Loss:   0.5543   Validation Accuracy: 0.597800\n",
      "Epoch 56, CIFAR-10 Batch 1:  Loss:   0.5355   Validation Accuracy: 0.595400\n",
      "Epoch 57, CIFAR-10 Batch 1:  Loss:   0.5435   Validation Accuracy: 0.595600\n",
      "Epoch 58, CIFAR-10 Batch 1:  Loss:   0.5272   Validation Accuracy: 0.595200\n",
      "Epoch 59, CIFAR-10 Batch 1:  Loss:   0.5192   Validation Accuracy: 0.593000\n",
      "Epoch 60, CIFAR-10 Batch 1:  Loss:   0.5094   Validation Accuracy: 0.597600\n",
      "Epoch 61, CIFAR-10 Batch 1:  Loss:   0.4890   Validation Accuracy: 0.596400\n",
      "Epoch 62, CIFAR-10 Batch 1:  Loss:   0.4725   Validation Accuracy: 0.596000\n",
      "Epoch 63, CIFAR-10 Batch 1:  Loss:   0.4703   Validation Accuracy: 0.597600\n",
      "Epoch 64, CIFAR-10 Batch 1:  Loss:   0.4767   Validation Accuracy: 0.596800\n",
      "Epoch 65, CIFAR-10 Batch 1:  Loss:   0.4540   Validation Accuracy: 0.602400\n",
      "Epoch 66, CIFAR-10 Batch 1:  Loss:   0.4480   Validation Accuracy: 0.597400\n",
      "Epoch 67, CIFAR-10 Batch 1:  Loss:   0.4360   Validation Accuracy: 0.599600\n",
      "Epoch 68, CIFAR-10 Batch 1:  Loss:   0.4227   Validation Accuracy: 0.603800\n",
      "Epoch 69, CIFAR-10 Batch 1:  Loss:   0.4337   Validation Accuracy: 0.601800\n",
      "Epoch 70, CIFAR-10 Batch 1:  Loss:   0.4253   Validation Accuracy: 0.598200\n",
      "Epoch 71, CIFAR-10 Batch 1:  Loss:   0.4099   Validation Accuracy: 0.591800\n",
      "Epoch 72, CIFAR-10 Batch 1:  Loss:   0.4101   Validation Accuracy: 0.596800\n",
      "Epoch 73, CIFAR-10 Batch 1:  Loss:   0.4039   Validation Accuracy: 0.595800\n",
      "Epoch 74, CIFAR-10 Batch 1:  Loss:   0.3844   Validation Accuracy: 0.600800\n",
      "Epoch 75, CIFAR-10 Batch 1:  Loss:   0.3794   Validation Accuracy: 0.596800\n",
      "Epoch 76, CIFAR-10 Batch 1:  Loss:   0.3642   Validation Accuracy: 0.606400\n",
      "Epoch 77, CIFAR-10 Batch 1:  Loss:   0.3623   Validation Accuracy: 0.601400\n",
      "Epoch 78, CIFAR-10 Batch 1:  Loss:   0.3620   Validation Accuracy: 0.605800\n",
      "Epoch 79, CIFAR-10 Batch 1:  Loss:   0.3440   Validation Accuracy: 0.598800\n",
      "Epoch 80, CIFAR-10 Batch 1:  Loss:   0.3546   Validation Accuracy: 0.602400\n",
      "Epoch 81, CIFAR-10 Batch 1:  Loss:   0.3189   Validation Accuracy: 0.606600\n",
      "Epoch 82, CIFAR-10 Batch 1:  Loss:   0.3133   Validation Accuracy: 0.609600\n",
      "Epoch 83, CIFAR-10 Batch 1:  Loss:   0.3105   Validation Accuracy: 0.600400\n",
      "Epoch 84, CIFAR-10 Batch 1:  Loss:   0.3017   Validation Accuracy: 0.606600\n",
      "Epoch 85, CIFAR-10 Batch 1:  Loss:   0.3158   Validation Accuracy: 0.603000\n",
      "Epoch 86, CIFAR-10 Batch 1:  Loss:   0.2996   Validation Accuracy: 0.600800\n",
      "Epoch 87, CIFAR-10 Batch 1:  Loss:   0.2993   Validation Accuracy: 0.605600\n",
      "Epoch 88, CIFAR-10 Batch 1:  Loss:   0.2880   Validation Accuracy: 0.601800\n",
      "Epoch 89, CIFAR-10 Batch 1:  Loss:   0.2845   Validation Accuracy: 0.605200\n",
      "Epoch 90, CIFAR-10 Batch 1:  Loss:   0.2612   Validation Accuracy: 0.608600\n",
      "Epoch 91, CIFAR-10 Batch 1:  Loss:   0.2646   Validation Accuracy: 0.608000\n",
      "Epoch 92, CIFAR-10 Batch 1:  Loss:   0.2448   Validation Accuracy: 0.610000\n",
      "Epoch 93, CIFAR-10 Batch 1:  Loss:   0.2496   Validation Accuracy: 0.611200\n",
      "Epoch 94, CIFAR-10 Batch 1:  Loss:   0.2460   Validation Accuracy: 0.608200\n",
      "Epoch 95, CIFAR-10 Batch 1:  Loss:   0.2459   Validation Accuracy: 0.609200\n",
      "Epoch 96, CIFAR-10 Batch 1:  Loss:   0.2346   Validation Accuracy: 0.618000\n",
      "Epoch 97, CIFAR-10 Batch 1:  Loss:   0.2357   Validation Accuracy: 0.610200\n",
      "Epoch 98, CIFAR-10 Batch 1:  Loss:   0.2274   Validation Accuracy: 0.615600\n",
      "Epoch 99, CIFAR-10 Batch 1:  Loss:   0.2242   Validation Accuracy: 0.617800\n",
      "Epoch 100, CIFAR-10 Batch 1:  Loss:   0.2075   Validation Accuracy: 0.610400\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "print('Checking the Training on a Single Batch...')\n",
    "with tf.Session() as sess:\n",
    "    # Initializing the variables\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    # Training cycle\n",
    "    for epoch in range(epochs):\n",
    "        batch_i = 1\n",
    "        for batch_features, batch_labels in helper.load_preprocess_training_batch(batch_i, batch_size):\n",
    "            train_neural_network(sess, optimizer, keep_probability, batch_features, batch_labels)\n",
    "        print('Epoch {:>2}, CIFAR-10 Batch {}:  '.format(epoch + 1, batch_i), end='')\n",
    "        print_stats(sess, batch_features, batch_labels, cost, accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fully Train the Model\n",
    "Now that you got a good accuracy with a single CIFAR-10 batch, try it with all five batches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training...\n",
      "Epoch  1, CIFAR-10 Batch 1:  Loss:   2.2996   Validation Accuracy: 0.103400\n",
      "Epoch  1, CIFAR-10 Batch 2:  Loss:   2.2880   Validation Accuracy: 0.122000\n",
      "Epoch  1, CIFAR-10 Batch 3:  Loss:   2.2282   Validation Accuracy: 0.173800\n",
      "Epoch  1, CIFAR-10 Batch 4:  Loss:   2.1043   Validation Accuracy: 0.216000\n",
      "Epoch  1, CIFAR-10 Batch 5:  Loss:   2.0246   Validation Accuracy: 0.273400\n",
      "Epoch  2, CIFAR-10 Batch 1:  Loss:   1.9340   Validation Accuracy: 0.308000\n",
      "Epoch  2, CIFAR-10 Batch 2:  Loss:   1.7976   Validation Accuracy: 0.370400\n",
      "Epoch  2, CIFAR-10 Batch 3:  Loss:   1.6940   Validation Accuracy: 0.372600\n",
      "Epoch  2, CIFAR-10 Batch 4:  Loss:   1.6175   Validation Accuracy: 0.412000\n",
      "Epoch  2, CIFAR-10 Batch 5:  Loss:   1.6360   Validation Accuracy: 0.417200\n",
      "Epoch  3, CIFAR-10 Batch 1:  Loss:   1.6541   Validation Accuracy: 0.426800\n",
      "Epoch  3, CIFAR-10 Batch 2:  Loss:   1.5391   Validation Accuracy: 0.461000\n",
      "Epoch  3, CIFAR-10 Batch 3:  Loss:   1.4604   Validation Accuracy: 0.456600\n",
      "Epoch  3, CIFAR-10 Batch 4:  Loss:   1.4154   Validation Accuracy: 0.480600\n",
      "Epoch  3, CIFAR-10 Batch 5:  Loss:   1.4664   Validation Accuracy: 0.481800\n",
      "Epoch  4, CIFAR-10 Batch 1:  Loss:   1.5149   Validation Accuracy: 0.487400\n",
      "Epoch  4, CIFAR-10 Batch 2:  Loss:   1.3738   Validation Accuracy: 0.507000\n",
      "Epoch  4, CIFAR-10 Batch 3:  Loss:   1.3347   Validation Accuracy: 0.496200\n",
      "Epoch  4, CIFAR-10 Batch 4:  Loss:   1.2994   Validation Accuracy: 0.509600\n",
      "Epoch  4, CIFAR-10 Batch 5:  Loss:   1.3539   Validation Accuracy: 0.511200\n",
      "Epoch  5, CIFAR-10 Batch 1:  Loss:   1.4377   Validation Accuracy: 0.503400\n",
      "Epoch  5, CIFAR-10 Batch 2:  Loss:   1.2893   Validation Accuracy: 0.527600\n",
      "Epoch  5, CIFAR-10 Batch 3:  Loss:   1.2324   Validation Accuracy: 0.524400\n",
      "Epoch  5, CIFAR-10 Batch 4:  Loss:   1.2268   Validation Accuracy: 0.527800\n",
      "Epoch  5, CIFAR-10 Batch 5:  Loss:   1.2718   Validation Accuracy: 0.529800\n",
      "Epoch  6, CIFAR-10 Batch 1:  Loss:   1.3655   Validation Accuracy: 0.530600\n",
      "Epoch  6, CIFAR-10 Batch 2:  Loss:   1.2273   Validation Accuracy: 0.532400\n",
      "Epoch  6, CIFAR-10 Batch 3:  Loss:   1.1841   Validation Accuracy: 0.530200\n",
      "Epoch  6, CIFAR-10 Batch 4:  Loss:   1.1847   Validation Accuracy: 0.539600\n",
      "Epoch  6, CIFAR-10 Batch 5:  Loss:   1.2289   Validation Accuracy: 0.545200\n",
      "Epoch  7, CIFAR-10 Batch 1:  Loss:   1.2822   Validation Accuracy: 0.552400\n",
      "Epoch  7, CIFAR-10 Batch 2:  Loss:   1.1570   Validation Accuracy: 0.555600\n",
      "Epoch  7, CIFAR-10 Batch 3:  Loss:   1.1254   Validation Accuracy: 0.552000\n",
      "Epoch  7, CIFAR-10 Batch 4:  Loss:   1.1229   Validation Accuracy: 0.555000\n",
      "Epoch  7, CIFAR-10 Batch 5:  Loss:   1.2002   Validation Accuracy: 0.557800\n",
      "Epoch  8, CIFAR-10 Batch 1:  Loss:   1.2766   Validation Accuracy: 0.553400\n",
      "Epoch  8, CIFAR-10 Batch 2:  Loss:   1.1181   Validation Accuracy: 0.562600\n",
      "Epoch  8, CIFAR-10 Batch 3:  Loss:   1.0897   Validation Accuracy: 0.565000\n",
      "Epoch  8, CIFAR-10 Batch 4:  Loss:   1.0817   Validation Accuracy: 0.567000\n",
      "Epoch  8, CIFAR-10 Batch 5:  Loss:   1.1434   Validation Accuracy: 0.561400\n",
      "Epoch  9, CIFAR-10 Batch 1:  Loss:   1.2226   Validation Accuracy: 0.562600\n",
      "Epoch  9, CIFAR-10 Batch 2:  Loss:   1.0708   Validation Accuracy: 0.568200\n",
      "Epoch  9, CIFAR-10 Batch 3:  Loss:   1.0530   Validation Accuracy: 0.570400\n",
      "Epoch  9, CIFAR-10 Batch 4:  Loss:   1.0483   Validation Accuracy: 0.576800\n",
      "Epoch  9, CIFAR-10 Batch 5:  Loss:   1.1181   Validation Accuracy: 0.568400\n",
      "Epoch 10, CIFAR-10 Batch 1:  Loss:   1.1848   Validation Accuracy: 0.577800\n",
      "Epoch 10, CIFAR-10 Batch 2:  Loss:   1.0619   Validation Accuracy: 0.582800\n",
      "Epoch 10, CIFAR-10 Batch 3:  Loss:   1.0348   Validation Accuracy: 0.574200\n",
      "Epoch 10, CIFAR-10 Batch 4:  Loss:   1.0154   Validation Accuracy: 0.583400\n",
      "Epoch 10, CIFAR-10 Batch 5:  Loss:   1.0735   Validation Accuracy: 0.579600\n",
      "Epoch 11, CIFAR-10 Batch 1:  Loss:   1.1658   Validation Accuracy: 0.577200\n",
      "Epoch 11, CIFAR-10 Batch 2:  Loss:   1.0225   Validation Accuracy: 0.585600\n",
      "Epoch 11, CIFAR-10 Batch 3:  Loss:   1.0165   Validation Accuracy: 0.579000\n",
      "Epoch 11, CIFAR-10 Batch 4:  Loss:   1.0175   Validation Accuracy: 0.579400\n",
      "Epoch 11, CIFAR-10 Batch 5:  Loss:   1.0676   Validation Accuracy: 0.583600\n",
      "Epoch 12, CIFAR-10 Batch 1:  Loss:   1.1453   Validation Accuracy: 0.589800\n",
      "Epoch 12, CIFAR-10 Batch 2:  Loss:   1.0183   Validation Accuracy: 0.594600\n",
      "Epoch 12, CIFAR-10 Batch 3:  Loss:   0.9836   Validation Accuracy: 0.591400\n",
      "Epoch 12, CIFAR-10 Batch 4:  Loss:   0.9775   Validation Accuracy: 0.601800\n",
      "Epoch 12, CIFAR-10 Batch 5:  Loss:   1.0512   Validation Accuracy: 0.588400\n",
      "Epoch 13, CIFAR-10 Batch 1:  Loss:   1.1195   Validation Accuracy: 0.593600\n",
      "Epoch 13, CIFAR-10 Batch 2:  Loss:   0.9865   Validation Accuracy: 0.599800\n",
      "Epoch 13, CIFAR-10 Batch 3:  Loss:   0.9551   Validation Accuracy: 0.593800\n",
      "Epoch 13, CIFAR-10 Batch 4:  Loss:   0.9498   Validation Accuracy: 0.602200\n",
      "Epoch 13, CIFAR-10 Batch 5:  Loss:   1.0334   Validation Accuracy: 0.590400\n",
      "Epoch 14, CIFAR-10 Batch 1:  Loss:   1.0919   Validation Accuracy: 0.595600\n",
      "Epoch 14, CIFAR-10 Batch 2:  Loss:   0.9757   Validation Accuracy: 0.602800\n",
      "Epoch 14, CIFAR-10 Batch 3:  Loss:   0.9288   Validation Accuracy: 0.592600\n",
      "Epoch 14, CIFAR-10 Batch 4:  Loss:   0.9294   Validation Accuracy: 0.607000\n",
      "Epoch 14, CIFAR-10 Batch 5:  Loss:   0.9918   Validation Accuracy: 0.599400\n",
      "Epoch 15, CIFAR-10 Batch 1:  Loss:   1.0559   Validation Accuracy: 0.603600\n",
      "Epoch 15, CIFAR-10 Batch 2:  Loss:   0.9524   Validation Accuracy: 0.611600\n",
      "Epoch 15, CIFAR-10 Batch 3:  Loss:   0.9222   Validation Accuracy: 0.602600\n",
      "Epoch 15, CIFAR-10 Batch 4:  Loss:   0.8960   Validation Accuracy: 0.614400\n",
      "Epoch 15, CIFAR-10 Batch 5:  Loss:   0.9661   Validation Accuracy: 0.612800\n",
      "Epoch 16, CIFAR-10 Batch 1:  Loss:   1.0522   Validation Accuracy: 0.600400\n",
      "Epoch 16, CIFAR-10 Batch 2:  Loss:   0.9282   Validation Accuracy: 0.611400\n",
      "Epoch 16, CIFAR-10 Batch 3:  Loss:   0.9073   Validation Accuracy: 0.605600\n",
      "Epoch 16, CIFAR-10 Batch 4:  Loss:   0.9103   Validation Accuracy: 0.612200\n",
      "Epoch 16, CIFAR-10 Batch 5:  Loss:   0.9503   Validation Accuracy: 0.610800\n",
      "Epoch 17, CIFAR-10 Batch 1:  Loss:   1.0292   Validation Accuracy: 0.606800\n",
      "Epoch 17, CIFAR-10 Batch 2:  Loss:   0.9236   Validation Accuracy: 0.618400\n",
      "Epoch 17, CIFAR-10 Batch 3:  Loss:   0.9023   Validation Accuracy: 0.610000\n",
      "Epoch 17, CIFAR-10 Batch 4:  Loss:   0.8858   Validation Accuracy: 0.618400\n",
      "Epoch 17, CIFAR-10 Batch 5:  Loss:   0.9289   Validation Accuracy: 0.616600\n",
      "Epoch 18, CIFAR-10 Batch 1:  Loss:   1.0359   Validation Accuracy: 0.607200\n",
      "Epoch 18, CIFAR-10 Batch 2:  Loss:   0.8907   Validation Accuracy: 0.618800\n",
      "Epoch 18, CIFAR-10 Batch 3:  Loss:   0.8799   Validation Accuracy: 0.610600\n",
      "Epoch 18, CIFAR-10 Batch 4:  Loss:   0.8700   Validation Accuracy: 0.619200\n",
      "Epoch 18, CIFAR-10 Batch 5:  Loss:   0.9182   Validation Accuracy: 0.616200\n",
      "Epoch 19, CIFAR-10 Batch 1:  Loss:   1.0184   Validation Accuracy: 0.617200\n",
      "Epoch 19, CIFAR-10 Batch 2:  Loss:   0.8763   Validation Accuracy: 0.625600\n",
      "Epoch 19, CIFAR-10 Batch 3:  Loss:   0.8480   Validation Accuracy: 0.618800\n",
      "Epoch 19, CIFAR-10 Batch 4:  Loss:   0.8429   Validation Accuracy: 0.624400\n",
      "Epoch 19, CIFAR-10 Batch 5:  Loss:   0.9088   Validation Accuracy: 0.623400\n",
      "Epoch 20, CIFAR-10 Batch 1:  Loss:   0.9965   Validation Accuracy: 0.611400\n",
      "Epoch 20, CIFAR-10 Batch 2:  Loss:   0.8611   Validation Accuracy: 0.626400\n",
      "Epoch 20, CIFAR-10 Batch 3:  Loss:   0.8321   Validation Accuracy: 0.621800\n",
      "Epoch 20, CIFAR-10 Batch 4:  Loss:   0.8460   Validation Accuracy: 0.624200\n",
      "Epoch 20, CIFAR-10 Batch 5:  Loss:   0.8690   Validation Accuracy: 0.624600\n",
      "Epoch 21, CIFAR-10 Batch 1:  Loss:   0.9743   Validation Accuracy: 0.613600\n",
      "Epoch 21, CIFAR-10 Batch 2:  Loss:   0.8499   Validation Accuracy: 0.628000\n",
      "Epoch 21, CIFAR-10 Batch 3:  Loss:   0.8040   Validation Accuracy: 0.628400\n",
      "Epoch 21, CIFAR-10 Batch 4:  Loss:   0.8215   Validation Accuracy: 0.630200\n",
      "Epoch 21, CIFAR-10 Batch 5:  Loss:   0.8660   Validation Accuracy: 0.624600\n",
      "Epoch 22, CIFAR-10 Batch 1:  Loss:   0.9441   Validation Accuracy: 0.625600\n",
      "Epoch 22, CIFAR-10 Batch 2:  Loss:   0.8371   Validation Accuracy: 0.634400\n",
      "Epoch 22, CIFAR-10 Batch 3:  Loss:   0.7971   Validation Accuracy: 0.627800\n",
      "Epoch 22, CIFAR-10 Batch 4:  Loss:   0.8166   Validation Accuracy: 0.633000\n",
      "Epoch 22, CIFAR-10 Batch 5:  Loss:   0.8415   Validation Accuracy: 0.629400\n",
      "Epoch 23, CIFAR-10 Batch 1:  Loss:   0.9382   Validation Accuracy: 0.628800\n",
      "Epoch 23, CIFAR-10 Batch 2:  Loss:   0.7986   Validation Accuracy: 0.631800\n",
      "Epoch 23, CIFAR-10 Batch 3:  Loss:   0.7756   Validation Accuracy: 0.628800\n",
      "Epoch 23, CIFAR-10 Batch 4:  Loss:   0.8053   Validation Accuracy: 0.628800\n",
      "Epoch 23, CIFAR-10 Batch 5:  Loss:   0.8256   Validation Accuracy: 0.635400\n",
      "Epoch 24, CIFAR-10 Batch 1:  Loss:   0.9093   Validation Accuracy: 0.628400\n",
      "Epoch 24, CIFAR-10 Batch 2:  Loss:   0.8148   Validation Accuracy: 0.631200\n",
      "Epoch 24, CIFAR-10 Batch 3:  Loss:   0.7487   Validation Accuracy: 0.638400\n",
      "Epoch 24, CIFAR-10 Batch 4:  Loss:   0.8000   Validation Accuracy: 0.630600\n",
      "Epoch 24, CIFAR-10 Batch 5:  Loss:   0.8022   Validation Accuracy: 0.632800\n",
      "Epoch 25, CIFAR-10 Batch 1:  Loss:   0.9167   Validation Accuracy: 0.625600\n",
      "Epoch 25, CIFAR-10 Batch 2:  Loss:   0.8083   Validation Accuracy: 0.636000\n",
      "Epoch 25, CIFAR-10 Batch 3:  Loss:   0.7464   Validation Accuracy: 0.637000\n",
      "Epoch 25, CIFAR-10 Batch 4:  Loss:   0.7693   Validation Accuracy: 0.635200\n",
      "Epoch 25, CIFAR-10 Batch 5:  Loss:   0.7951   Validation Accuracy: 0.635000\n",
      "Epoch 26, CIFAR-10 Batch 1:  Loss:   0.8819   Validation Accuracy: 0.636600\n",
      "Epoch 26, CIFAR-10 Batch 2:  Loss:   0.8114   Validation Accuracy: 0.629600\n",
      "Epoch 26, CIFAR-10 Batch 3:  Loss:   0.7264   Validation Accuracy: 0.635800\n",
      "Epoch 26, CIFAR-10 Batch 4:  Loss:   0.7710   Validation Accuracy: 0.634800\n",
      "Epoch 26, CIFAR-10 Batch 5:  Loss:   0.7816   Validation Accuracy: 0.638000\n",
      "Epoch 27, CIFAR-10 Batch 1:  Loss:   0.8674   Validation Accuracy: 0.630600\n",
      "Epoch 27, CIFAR-10 Batch 2:  Loss:   0.7714   Validation Accuracy: 0.634800\n",
      "Epoch 27, CIFAR-10 Batch 3:  Loss:   0.7288   Validation Accuracy: 0.635000\n",
      "Epoch 27, CIFAR-10 Batch 4:  Loss:   0.7273   Validation Accuracy: 0.639200\n",
      "Epoch 27, CIFAR-10 Batch 5:  Loss:   0.7764   Validation Accuracy: 0.637400\n",
      "Epoch 28, CIFAR-10 Batch 1:  Loss:   0.8851   Validation Accuracy: 0.636600\n",
      "Epoch 28, CIFAR-10 Batch 2:  Loss:   0.7607   Validation Accuracy: 0.637800\n",
      "Epoch 28, CIFAR-10 Batch 3:  Loss:   0.7210   Validation Accuracy: 0.636000\n",
      "Epoch 28, CIFAR-10 Batch 4:  Loss:   0.7430   Validation Accuracy: 0.640000\n",
      "Epoch 28, CIFAR-10 Batch 5:  Loss:   0.7711   Validation Accuracy: 0.638600\n",
      "Epoch 29, CIFAR-10 Batch 1:  Loss:   0.8533   Validation Accuracy: 0.636400\n",
      "Epoch 29, CIFAR-10 Batch 2:  Loss:   0.7629   Validation Accuracy: 0.643600\n",
      "Epoch 29, CIFAR-10 Batch 3:  Loss:   0.7046   Validation Accuracy: 0.637200\n",
      "Epoch 29, CIFAR-10 Batch 4:  Loss:   0.7233   Validation Accuracy: 0.639600\n",
      "Epoch 29, CIFAR-10 Batch 5:  Loss:   0.7522   Validation Accuracy: 0.643400\n",
      "Epoch 30, CIFAR-10 Batch 1:  Loss:   0.8482   Validation Accuracy: 0.637800\n",
      "Epoch 30, CIFAR-10 Batch 2:  Loss:   0.7461   Validation Accuracy: 0.637600\n",
      "Epoch 30, CIFAR-10 Batch 3:  Loss:   0.6905   Validation Accuracy: 0.637200\n",
      "Epoch 30, CIFAR-10 Batch 4:  Loss:   0.7206   Validation Accuracy: 0.640000\n",
      "Epoch 30, CIFAR-10 Batch 5:  Loss:   0.7533   Validation Accuracy: 0.640000\n",
      "Epoch 31, CIFAR-10 Batch 1:  Loss:   0.8238   Validation Accuracy: 0.642400\n",
      "Epoch 31, CIFAR-10 Batch 2:  Loss:   0.7307   Validation Accuracy: 0.635200\n",
      "Epoch 31, CIFAR-10 Batch 3:  Loss:   0.6713   Validation Accuracy: 0.635800\n",
      "Epoch 31, CIFAR-10 Batch 4:  Loss:   0.7211   Validation Accuracy: 0.640200\n",
      "Epoch 31, CIFAR-10 Batch 5:  Loss:   0.7197   Validation Accuracy: 0.638400\n",
      "Epoch 32, CIFAR-10 Batch 1:  Loss:   0.8319   Validation Accuracy: 0.633000\n",
      "Epoch 32, CIFAR-10 Batch 2:  Loss:   0.7199   Validation Accuracy: 0.644800\n",
      "Epoch 32, CIFAR-10 Batch 3:  Loss:   0.6581   Validation Accuracy: 0.645600\n",
      "Epoch 32, CIFAR-10 Batch 4:  Loss:   0.7074   Validation Accuracy: 0.644400\n",
      "Epoch 32, CIFAR-10 Batch 5:  Loss:   0.7366   Validation Accuracy: 0.639800\n",
      "Epoch 33, CIFAR-10 Batch 1:  Loss:   0.8213   Validation Accuracy: 0.643600\n",
      "Epoch 33, CIFAR-10 Batch 2:  Loss:   0.7124   Validation Accuracy: 0.639400\n",
      "Epoch 33, CIFAR-10 Batch 3:  Loss:   0.6543   Validation Accuracy: 0.648200\n",
      "Epoch 33, CIFAR-10 Batch 4:  Loss:   0.7056   Validation Accuracy: 0.644600\n",
      "Epoch 33, CIFAR-10 Batch 5:  Loss:   0.7216   Validation Accuracy: 0.639400\n",
      "Epoch 34, CIFAR-10 Batch 1:  Loss:   0.7837   Validation Accuracy: 0.641200\n",
      "Epoch 34, CIFAR-10 Batch 2:  Loss:   0.7020   Validation Accuracy: 0.645400\n",
      "Epoch 34, CIFAR-10 Batch 3:  Loss:   0.6762   Validation Accuracy: 0.636800\n",
      "Epoch 34, CIFAR-10 Batch 4:  Loss:   0.7065   Validation Accuracy: 0.641200\n",
      "Epoch 34, CIFAR-10 Batch 5:  Loss:   0.7224   Validation Accuracy: 0.644800\n",
      "Epoch 35, CIFAR-10 Batch 1:  Loss:   0.7875   Validation Accuracy: 0.639200\n",
      "Epoch 35, CIFAR-10 Batch 2:  Loss:   0.6976   Validation Accuracy: 0.652800\n",
      "Epoch 35, CIFAR-10 Batch 3:  Loss:   0.6289   Validation Accuracy: 0.644000\n",
      "Epoch 35, CIFAR-10 Batch 4:  Loss:   0.6897   Validation Accuracy: 0.650600\n",
      "Epoch 35, CIFAR-10 Batch 5:  Loss:   0.7118   Validation Accuracy: 0.633400\n",
      "Epoch 36, CIFAR-10 Batch 1:  Loss:   0.7780   Validation Accuracy: 0.650800\n",
      "Epoch 36, CIFAR-10 Batch 2:  Loss:   0.6943   Validation Accuracy: 0.646000\n",
      "Epoch 36, CIFAR-10 Batch 3:  Loss:   0.6233   Validation Accuracy: 0.646800\n",
      "Epoch 36, CIFAR-10 Batch 4:  Loss:   0.6843   Validation Accuracy: 0.646600\n",
      "Epoch 36, CIFAR-10 Batch 5:  Loss:   0.7064   Validation Accuracy: 0.648600\n",
      "Epoch 37, CIFAR-10 Batch 1:  Loss:   0.7497   Validation Accuracy: 0.650200\n",
      "Epoch 37, CIFAR-10 Batch 2:  Loss:   0.6703   Validation Accuracy: 0.644000\n",
      "Epoch 37, CIFAR-10 Batch 3:  Loss:   0.6132   Validation Accuracy: 0.649600\n",
      "Epoch 37, CIFAR-10 Batch 4:  Loss:   0.6751   Validation Accuracy: 0.649800\n",
      "Epoch 37, CIFAR-10 Batch 5:  Loss:   0.6917   Validation Accuracy: 0.651400\n",
      "Epoch 38, CIFAR-10 Batch 1:  Loss:   0.7719   Validation Accuracy: 0.648600\n",
      "Epoch 38, CIFAR-10 Batch 2:  Loss:   0.6586   Validation Accuracy: 0.651800\n",
      "Epoch 38, CIFAR-10 Batch 3:  Loss:   0.6055   Validation Accuracy: 0.650000\n",
      "Epoch 38, CIFAR-10 Batch 4:  Loss:   0.6507   Validation Accuracy: 0.650600\n",
      "Epoch 38, CIFAR-10 Batch 5:  Loss:   0.6683   Validation Accuracy: 0.651200\n",
      "Epoch 39, CIFAR-10 Batch 1:  Loss:   0.7543   Validation Accuracy: 0.641000\n",
      "Epoch 39, CIFAR-10 Batch 2:  Loss:   0.6540   Validation Accuracy: 0.649800\n",
      "Epoch 39, CIFAR-10 Batch 3:  Loss:   0.5959   Validation Accuracy: 0.654200\n",
      "Epoch 39, CIFAR-10 Batch 4:  Loss:   0.6479   Validation Accuracy: 0.651200\n",
      "Epoch 39, CIFAR-10 Batch 5:  Loss:   0.6675   Validation Accuracy: 0.651600\n",
      "Epoch 40, CIFAR-10 Batch 1:  Loss:   0.7354   Validation Accuracy: 0.648600\n",
      "Epoch 40, CIFAR-10 Batch 2:  Loss:   0.6669   Validation Accuracy: 0.647000\n",
      "Epoch 40, CIFAR-10 Batch 3:  Loss:   0.5925   Validation Accuracy: 0.648200\n",
      "Epoch 40, CIFAR-10 Batch 4:  Loss:   0.6636   Validation Accuracy: 0.648400\n",
      "Epoch 40, CIFAR-10 Batch 5:  Loss:   0.6511   Validation Accuracy: 0.651400\n",
      "Epoch 41, CIFAR-10 Batch 1:  Loss:   0.7346   Validation Accuracy: 0.656000\n",
      "Epoch 41, CIFAR-10 Batch 2:  Loss:   0.6321   Validation Accuracy: 0.651200\n",
      "Epoch 41, CIFAR-10 Batch 3:  Loss:   0.5954   Validation Accuracy: 0.654600\n",
      "Epoch 41, CIFAR-10 Batch 4:  Loss:   0.6325   Validation Accuracy: 0.657800\n",
      "Epoch 41, CIFAR-10 Batch 5:  Loss:   0.6594   Validation Accuracy: 0.651000\n",
      "Epoch 42, CIFAR-10 Batch 1:  Loss:   0.7379   Validation Accuracy: 0.652200\n",
      "Epoch 42, CIFAR-10 Batch 2:  Loss:   0.6419   Validation Accuracy: 0.657800\n",
      "Epoch 42, CIFAR-10 Batch 3:  Loss:   0.5915   Validation Accuracy: 0.657400\n",
      "Epoch 42, CIFAR-10 Batch 4:  Loss:   0.6379   Validation Accuracy: 0.653400\n",
      "Epoch 42, CIFAR-10 Batch 5:  Loss:   0.6335   Validation Accuracy: 0.655800\n",
      "Epoch 43, CIFAR-10 Batch 1:  Loss:   0.7276   Validation Accuracy: 0.650000\n",
      "Epoch 43, CIFAR-10 Batch 2:  Loss:   0.6190   Validation Accuracy: 0.657200\n",
      "Epoch 43, CIFAR-10 Batch 3:  Loss:   0.5733   Validation Accuracy: 0.660400\n",
      "Epoch 43, CIFAR-10 Batch 4:  Loss:   0.6232   Validation Accuracy: 0.654200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 43, CIFAR-10 Batch 5:  Loss:   0.6359   Validation Accuracy: 0.658000\n",
      "Epoch 44, CIFAR-10 Batch 1:  Loss:   0.7114   Validation Accuracy: 0.654800\n",
      "Epoch 44, CIFAR-10 Batch 2:  Loss:   0.6216   Validation Accuracy: 0.651800\n",
      "Epoch 44, CIFAR-10 Batch 3:  Loss:   0.5750   Validation Accuracy: 0.655600\n",
      "Epoch 44, CIFAR-10 Batch 4:  Loss:   0.6302   Validation Accuracy: 0.653400\n",
      "Epoch 44, CIFAR-10 Batch 5:  Loss:   0.6213   Validation Accuracy: 0.654600\n",
      "Epoch 45, CIFAR-10 Batch 1:  Loss:   0.7012   Validation Accuracy: 0.654000\n",
      "Epoch 45, CIFAR-10 Batch 2:  Loss:   0.6248   Validation Accuracy: 0.657800\n",
      "Epoch 45, CIFAR-10 Batch 3:  Loss:   0.5665   Validation Accuracy: 0.656200\n",
      "Epoch 45, CIFAR-10 Batch 4:  Loss:   0.6077   Validation Accuracy: 0.654400\n",
      "Epoch 45, CIFAR-10 Batch 5:  Loss:   0.6210   Validation Accuracy: 0.650600\n",
      "Epoch 46, CIFAR-10 Batch 1:  Loss:   0.6961   Validation Accuracy: 0.658600\n",
      "Epoch 46, CIFAR-10 Batch 2:  Loss:   0.6179   Validation Accuracy: 0.658800\n",
      "Epoch 46, CIFAR-10 Batch 3:  Loss:   0.5530   Validation Accuracy: 0.654600\n",
      "Epoch 46, CIFAR-10 Batch 4:  Loss:   0.5924   Validation Accuracy: 0.660400\n",
      "Epoch 46, CIFAR-10 Batch 5:  Loss:   0.5937   Validation Accuracy: 0.656800\n",
      "Epoch 47, CIFAR-10 Batch 1:  Loss:   0.6755   Validation Accuracy: 0.653000\n",
      "Epoch 47, CIFAR-10 Batch 2:  Loss:   0.6167   Validation Accuracy: 0.656400\n",
      "Epoch 47, CIFAR-10 Batch 3:  Loss:   0.5469   Validation Accuracy: 0.654000\n",
      "Epoch 47, CIFAR-10 Batch 4:  Loss:   0.6104   Validation Accuracy: 0.649200\n",
      "Epoch 47, CIFAR-10 Batch 5:  Loss:   0.6234   Validation Accuracy: 0.651000\n",
      "Epoch 48, CIFAR-10 Batch 1:  Loss:   0.6766   Validation Accuracy: 0.656000\n",
      "Epoch 48, CIFAR-10 Batch 2:  Loss:   0.5894   Validation Accuracy: 0.657600\n",
      "Epoch 48, CIFAR-10 Batch 3:  Loss:   0.5413   Validation Accuracy: 0.658800\n",
      "Epoch 48, CIFAR-10 Batch 4:  Loss:   0.5824   Validation Accuracy: 0.660800\n",
      "Epoch 48, CIFAR-10 Batch 5:  Loss:   0.6052   Validation Accuracy: 0.661000\n",
      "Epoch 49, CIFAR-10 Batch 1:  Loss:   0.6496   Validation Accuracy: 0.658600\n",
      "Epoch 49, CIFAR-10 Batch 2:  Loss:   0.5904   Validation Accuracy: 0.658400\n",
      "Epoch 49, CIFAR-10 Batch 3:  Loss:   0.5196   Validation Accuracy: 0.657600\n",
      "Epoch 49, CIFAR-10 Batch 4:  Loss:   0.5974   Validation Accuracy: 0.645600\n",
      "Epoch 49, CIFAR-10 Batch 5:  Loss:   0.5987   Validation Accuracy: 0.657600\n",
      "Epoch 50, CIFAR-10 Batch 1:  Loss:   0.6595   Validation Accuracy: 0.659400\n",
      "Epoch 50, CIFAR-10 Batch 2:  Loss:   0.5936   Validation Accuracy: 0.655800\n",
      "Epoch 50, CIFAR-10 Batch 3:  Loss:   0.5481   Validation Accuracy: 0.653800\n",
      "Epoch 50, CIFAR-10 Batch 4:  Loss:   0.5690   Validation Accuracy: 0.651800\n",
      "Epoch 50, CIFAR-10 Batch 5:  Loss:   0.5938   Validation Accuracy: 0.656000\n",
      "Epoch 51, CIFAR-10 Batch 1:  Loss:   0.6492   Validation Accuracy: 0.656200\n",
      "Epoch 51, CIFAR-10 Batch 2:  Loss:   0.5867   Validation Accuracy: 0.661000\n",
      "Epoch 51, CIFAR-10 Batch 3:  Loss:   0.5077   Validation Accuracy: 0.659000\n",
      "Epoch 51, CIFAR-10 Batch 4:  Loss:   0.5600   Validation Accuracy: 0.651400\n",
      "Epoch 51, CIFAR-10 Batch 5:  Loss:   0.5654   Validation Accuracy: 0.658400\n",
      "Epoch 52, CIFAR-10 Batch 1:  Loss:   0.6392   Validation Accuracy: 0.663800\n",
      "Epoch 52, CIFAR-10 Batch 2:  Loss:   0.5656   Validation Accuracy: 0.662200\n",
      "Epoch 52, CIFAR-10 Batch 3:  Loss:   0.5328   Validation Accuracy: 0.653600\n",
      "Epoch 52, CIFAR-10 Batch 4:  Loss:   0.5728   Validation Accuracy: 0.654600\n",
      "Epoch 52, CIFAR-10 Batch 5:  Loss:   0.5709   Validation Accuracy: 0.657000\n",
      "Epoch 53, CIFAR-10 Batch 1:  Loss:   0.6272   Validation Accuracy: 0.661000\n",
      "Epoch 53, CIFAR-10 Batch 2:  Loss:   0.5605   Validation Accuracy: 0.656600\n",
      "Epoch 53, CIFAR-10 Batch 3:  Loss:   0.5377   Validation Accuracy: 0.652600\n",
      "Epoch 53, CIFAR-10 Batch 4:  Loss:   0.5528   Validation Accuracy: 0.655600\n",
      "Epoch 53, CIFAR-10 Batch 5:  Loss:   0.5691   Validation Accuracy: 0.659600\n",
      "Epoch 54, CIFAR-10 Batch 1:  Loss:   0.6167   Validation Accuracy: 0.663200\n",
      "Epoch 54, CIFAR-10 Batch 2:  Loss:   0.5428   Validation Accuracy: 0.657800\n",
      "Epoch 54, CIFAR-10 Batch 3:  Loss:   0.5354   Validation Accuracy: 0.651000\n",
      "Epoch 54, CIFAR-10 Batch 4:  Loss:   0.5750   Validation Accuracy: 0.647600\n",
      "Epoch 54, CIFAR-10 Batch 5:  Loss:   0.5769   Validation Accuracy: 0.661400\n",
      "Epoch 55, CIFAR-10 Batch 1:  Loss:   0.6101   Validation Accuracy: 0.663600\n",
      "Epoch 55, CIFAR-10 Batch 2:  Loss:   0.5415   Validation Accuracy: 0.657600\n",
      "Epoch 55, CIFAR-10 Batch 3:  Loss:   0.5239   Validation Accuracy: 0.654200\n",
      "Epoch 55, CIFAR-10 Batch 4:  Loss:   0.5804   Validation Accuracy: 0.646200\n",
      "Epoch 55, CIFAR-10 Batch 5:  Loss:   0.5738   Validation Accuracy: 0.658400\n",
      "Epoch 56, CIFAR-10 Batch 1:  Loss:   0.6078   Validation Accuracy: 0.656200\n",
      "Epoch 56, CIFAR-10 Batch 2:  Loss:   0.5381   Validation Accuracy: 0.653200\n",
      "Epoch 56, CIFAR-10 Batch 3:  Loss:   0.5026   Validation Accuracy: 0.657400\n",
      "Epoch 56, CIFAR-10 Batch 4:  Loss:   0.5367   Validation Accuracy: 0.664000\n",
      "Epoch 56, CIFAR-10 Batch 5:  Loss:   0.5481   Validation Accuracy: 0.660400\n",
      "Epoch 57, CIFAR-10 Batch 1:  Loss:   0.6070   Validation Accuracy: 0.660000\n",
      "Epoch 57, CIFAR-10 Batch 2:  Loss:   0.5422   Validation Accuracy: 0.658600\n",
      "Epoch 57, CIFAR-10 Batch 3:  Loss:   0.5120   Validation Accuracy: 0.656600\n",
      "Epoch 57, CIFAR-10 Batch 4:  Loss:   0.5374   Validation Accuracy: 0.658400\n",
      "Epoch 57, CIFAR-10 Batch 5:  Loss:   0.5373   Validation Accuracy: 0.665000\n",
      "Epoch 58, CIFAR-10 Batch 1:  Loss:   0.5946   Validation Accuracy: 0.662000\n",
      "Epoch 58, CIFAR-10 Batch 2:  Loss:   0.5227   Validation Accuracy: 0.663600\n",
      "Epoch 58, CIFAR-10 Batch 3:  Loss:   0.4868   Validation Accuracy: 0.658000\n",
      "Epoch 58, CIFAR-10 Batch 4:  Loss:   0.5697   Validation Accuracy: 0.650200\n",
      "Epoch 58, CIFAR-10 Batch 5:  Loss:   0.5403   Validation Accuracy: 0.662400\n",
      "Epoch 59, CIFAR-10 Batch 1:  Loss:   0.5939   Validation Accuracy: 0.654000\n",
      "Epoch 59, CIFAR-10 Batch 2:  Loss:   0.5346   Validation Accuracy: 0.659400\n",
      "Epoch 59, CIFAR-10 Batch 3:  Loss:   0.5113   Validation Accuracy: 0.653000\n",
      "Epoch 59, CIFAR-10 Batch 4:  Loss:   0.5368   Validation Accuracy: 0.656200\n",
      "Epoch 59, CIFAR-10 Batch 5:  Loss:   0.5439   Validation Accuracy: 0.663200\n",
      "Epoch 60, CIFAR-10 Batch 1:  Loss:   0.6112   Validation Accuracy: 0.658000\n",
      "Epoch 60, CIFAR-10 Batch 2:  Loss:   0.5297   Validation Accuracy: 0.659400\n",
      "Epoch 60, CIFAR-10 Batch 3:  Loss:   0.4916   Validation Accuracy: 0.658200\n",
      "Epoch 60, CIFAR-10 Batch 4:  Loss:   0.5221   Validation Accuracy: 0.661200\n",
      "Epoch 60, CIFAR-10 Batch 5:  Loss:   0.5200   Validation Accuracy: 0.663800\n",
      "Epoch 61, CIFAR-10 Batch 1:  Loss:   0.5728   Validation Accuracy: 0.658400\n",
      "Epoch 61, CIFAR-10 Batch 2:  Loss:   0.5152   Validation Accuracy: 0.668200\n",
      "Epoch 61, CIFAR-10 Batch 3:  Loss:   0.4683   Validation Accuracy: 0.659400\n",
      "Epoch 61, CIFAR-10 Batch 4:  Loss:   0.5334   Validation Accuracy: 0.657000\n",
      "Epoch 61, CIFAR-10 Batch 5:  Loss:   0.5245   Validation Accuracy: 0.660800\n",
      "Epoch 62, CIFAR-10 Batch 1:  Loss:   0.5690   Validation Accuracy: 0.663000\n",
      "Epoch 62, CIFAR-10 Batch 2:  Loss:   0.5162   Validation Accuracy: 0.660800\n",
      "Epoch 62, CIFAR-10 Batch 3:  Loss:   0.4695   Validation Accuracy: 0.658000\n",
      "Epoch 62, CIFAR-10 Batch 4:  Loss:   0.5368   Validation Accuracy: 0.653800\n",
      "Epoch 62, CIFAR-10 Batch 5:  Loss:   0.5162   Validation Accuracy: 0.663800\n",
      "Epoch 63, CIFAR-10 Batch 1:  Loss:   0.5769   Validation Accuracy: 0.662600\n",
      "Epoch 63, CIFAR-10 Batch 2:  Loss:   0.5085   Validation Accuracy: 0.662800\n",
      "Epoch 63, CIFAR-10 Batch 3:  Loss:   0.4727   Validation Accuracy: 0.658800\n",
      "Epoch 63, CIFAR-10 Batch 4:  Loss:   0.5029   Validation Accuracy: 0.662800\n",
      "Epoch 63, CIFAR-10 Batch 5:  Loss:   0.5203   Validation Accuracy: 0.655000\n",
      "Epoch 64, CIFAR-10 Batch 1:  Loss:   0.5755   Validation Accuracy: 0.662400\n",
      "Epoch 64, CIFAR-10 Batch 2:  Loss:   0.5345   Validation Accuracy: 0.655600\n",
      "Epoch 64, CIFAR-10 Batch 3:  Loss:   0.4562   Validation Accuracy: 0.655800\n",
      "Epoch 64, CIFAR-10 Batch 4:  Loss:   0.5091   Validation Accuracy: 0.662400\n",
      "Epoch 64, CIFAR-10 Batch 5:  Loss:   0.5290   Validation Accuracy: 0.664000\n",
      "Epoch 65, CIFAR-10 Batch 1:  Loss:   0.5666   Validation Accuracy: 0.664000\n",
      "Epoch 65, CIFAR-10 Batch 2:  Loss:   0.5113   Validation Accuracy: 0.663800\n",
      "Epoch 65, CIFAR-10 Batch 3:  Loss:   0.4546   Validation Accuracy: 0.659600\n",
      "Epoch 65, CIFAR-10 Batch 4:  Loss:   0.5113   Validation Accuracy: 0.662400\n",
      "Epoch 65, CIFAR-10 Batch 5:  Loss:   0.5116   Validation Accuracy: 0.662200\n",
      "Epoch 66, CIFAR-10 Batch 1:  Loss:   0.5663   Validation Accuracy: 0.665200\n",
      "Epoch 66, CIFAR-10 Batch 2:  Loss:   0.5025   Validation Accuracy: 0.663800\n",
      "Epoch 66, CIFAR-10 Batch 3:  Loss:   0.4708   Validation Accuracy: 0.660800\n",
      "Epoch 66, CIFAR-10 Batch 4:  Loss:   0.4792   Validation Accuracy: 0.663800\n",
      "Epoch 66, CIFAR-10 Batch 5:  Loss:   0.4906   Validation Accuracy: 0.668200\n",
      "Epoch 67, CIFAR-10 Batch 1:  Loss:   0.5546   Validation Accuracy: 0.664400\n",
      "Epoch 67, CIFAR-10 Batch 2:  Loss:   0.5080   Validation Accuracy: 0.662800\n",
      "Epoch 67, CIFAR-10 Batch 3:  Loss:   0.4519   Validation Accuracy: 0.658600\n",
      "Epoch 67, CIFAR-10 Batch 4:  Loss:   0.4922   Validation Accuracy: 0.660600\n",
      "Epoch 67, CIFAR-10 Batch 5:  Loss:   0.4955   Validation Accuracy: 0.665000\n",
      "Epoch 68, CIFAR-10 Batch 1:  Loss:   0.5417   Validation Accuracy: 0.664200\n",
      "Epoch 68, CIFAR-10 Batch 2:  Loss:   0.4901   Validation Accuracy: 0.657400\n",
      "Epoch 68, CIFAR-10 Batch 3:  Loss:   0.4499   Validation Accuracy: 0.662600\n",
      "Epoch 68, CIFAR-10 Batch 4:  Loss:   0.4756   Validation Accuracy: 0.666200\n",
      "Epoch 68, CIFAR-10 Batch 5:  Loss:   0.4988   Validation Accuracy: 0.663000\n",
      "Epoch 69, CIFAR-10 Batch 1:  Loss:   0.5537   Validation Accuracy: 0.664400\n",
      "Epoch 69, CIFAR-10 Batch 2:  Loss:   0.4776   Validation Accuracy: 0.664400\n",
      "Epoch 69, CIFAR-10 Batch 3:  Loss:   0.4494   Validation Accuracy: 0.659600\n",
      "Epoch 69, CIFAR-10 Batch 4:  Loss:   0.4647   Validation Accuracy: 0.663800\n",
      "Epoch 69, CIFAR-10 Batch 5:  Loss:   0.4785   Validation Accuracy: 0.667400\n",
      "Epoch 70, CIFAR-10 Batch 1:  Loss:   0.5633   Validation Accuracy: 0.662200\n",
      "Epoch 70, CIFAR-10 Batch 2:  Loss:   0.4871   Validation Accuracy: 0.665400\n",
      "Epoch 70, CIFAR-10 Batch 3:  Loss:   0.4543   Validation Accuracy: 0.664400\n",
      "Epoch 70, CIFAR-10 Batch 4:  Loss:   0.4763   Validation Accuracy: 0.662800\n",
      "Epoch 70, CIFAR-10 Batch 5:  Loss:   0.5036   Validation Accuracy: 0.663200\n",
      "Epoch 71, CIFAR-10 Batch 1:  Loss:   0.5454   Validation Accuracy: 0.668000\n",
      "Epoch 71, CIFAR-10 Batch 2:  Loss:   0.4718   Validation Accuracy: 0.663000\n",
      "Epoch 71, CIFAR-10 Batch 3:  Loss:   0.4493   Validation Accuracy: 0.662000\n",
      "Epoch 71, CIFAR-10 Batch 4:  Loss:   0.4716   Validation Accuracy: 0.665800\n",
      "Epoch 71, CIFAR-10 Batch 5:  Loss:   0.4690   Validation Accuracy: 0.668600\n",
      "Epoch 72, CIFAR-10 Batch 1:  Loss:   0.5203   Validation Accuracy: 0.668200\n",
      "Epoch 72, CIFAR-10 Batch 2:  Loss:   0.4870   Validation Accuracy: 0.662000\n",
      "Epoch 72, CIFAR-10 Batch 3:  Loss:   0.4361   Validation Accuracy: 0.660800\n",
      "Epoch 72, CIFAR-10 Batch 4:  Loss:   0.4616   Validation Accuracy: 0.663400\n",
      "Epoch 72, CIFAR-10 Batch 5:  Loss:   0.4824   Validation Accuracy: 0.664600\n",
      "Epoch 73, CIFAR-10 Batch 1:  Loss:   0.5412   Validation Accuracy: 0.668200\n",
      "Epoch 73, CIFAR-10 Batch 2:  Loss:   0.4666   Validation Accuracy: 0.664800\n",
      "Epoch 73, CIFAR-10 Batch 3:  Loss:   0.4324   Validation Accuracy: 0.667200\n",
      "Epoch 73, CIFAR-10 Batch 4:  Loss:   0.4444   Validation Accuracy: 0.659400\n",
      "Epoch 73, CIFAR-10 Batch 5:  Loss:   0.4664   Validation Accuracy: 0.667200\n",
      "Epoch 74, CIFAR-10 Batch 1:  Loss:   0.5139   Validation Accuracy: 0.666400\n",
      "Epoch 74, CIFAR-10 Batch 2:  Loss:   0.4748   Validation Accuracy: 0.665800\n",
      "Epoch 74, CIFAR-10 Batch 3:  Loss:   0.4187   Validation Accuracy: 0.660400\n",
      "Epoch 74, CIFAR-10 Batch 4:  Loss:   0.4557   Validation Accuracy: 0.667200\n",
      "Epoch 74, CIFAR-10 Batch 5:  Loss:   0.4596   Validation Accuracy: 0.663400\n",
      "Epoch 75, CIFAR-10 Batch 1:  Loss:   0.5027   Validation Accuracy: 0.667800\n",
      "Epoch 75, CIFAR-10 Batch 2:  Loss:   0.4525   Validation Accuracy: 0.666400\n",
      "Epoch 75, CIFAR-10 Batch 3:  Loss:   0.4110   Validation Accuracy: 0.661200\n",
      "Epoch 75, CIFAR-10 Batch 4:  Loss:   0.4250   Validation Accuracy: 0.664800\n",
      "Epoch 75, CIFAR-10 Batch 5:  Loss:   0.4694   Validation Accuracy: 0.669600\n",
      "Epoch 76, CIFAR-10 Batch 1:  Loss:   0.5243   Validation Accuracy: 0.659200\n",
      "Epoch 76, CIFAR-10 Batch 2:  Loss:   0.4500   Validation Accuracy: 0.660200\n",
      "Epoch 76, CIFAR-10 Batch 3:  Loss:   0.4206   Validation Accuracy: 0.654800\n",
      "Epoch 76, CIFAR-10 Batch 4:  Loss:   0.4444   Validation Accuracy: 0.664400\n",
      "Epoch 76, CIFAR-10 Batch 5:  Loss:   0.4444   Validation Accuracy: 0.668400\n",
      "Epoch 77, CIFAR-10 Batch 1:  Loss:   0.5196   Validation Accuracy: 0.656000\n",
      "Epoch 77, CIFAR-10 Batch 2:  Loss:   0.4672   Validation Accuracy: 0.663200\n",
      "Epoch 77, CIFAR-10 Batch 3:  Loss:   0.4161   Validation Accuracy: 0.656600\n",
      "Epoch 77, CIFAR-10 Batch 4:  Loss:   0.4470   Validation Accuracy: 0.666600\n",
      "Epoch 77, CIFAR-10 Batch 5:  Loss:   0.4454   Validation Accuracy: 0.670400\n",
      "Epoch 78, CIFAR-10 Batch 1:  Loss:   0.4937   Validation Accuracy: 0.668000\n",
      "Epoch 78, CIFAR-10 Batch 2:  Loss:   0.4724   Validation Accuracy: 0.658200\n",
      "Epoch 78, CIFAR-10 Batch 3:  Loss:   0.4096   Validation Accuracy: 0.657800\n",
      "Epoch 78, CIFAR-10 Batch 4:  Loss:   0.4238   Validation Accuracy: 0.667200\n",
      "Epoch 78, CIFAR-10 Batch 5:  Loss:   0.4608   Validation Accuracy: 0.660000\n",
      "Epoch 79, CIFAR-10 Batch 1:  Loss:   0.4986   Validation Accuracy: 0.661800\n",
      "Epoch 79, CIFAR-10 Batch 2:  Loss:   0.4689   Validation Accuracy: 0.666000\n",
      "Epoch 79, CIFAR-10 Batch 3:  Loss:   0.4151   Validation Accuracy: 0.661200\n",
      "Epoch 79, CIFAR-10 Batch 4:  Loss:   0.4409   Validation Accuracy: 0.668400\n",
      "Epoch 79, CIFAR-10 Batch 5:  Loss:   0.4365   Validation Accuracy: 0.670600\n",
      "Epoch 80, CIFAR-10 Batch 1:  Loss:   0.5001   Validation Accuracy: 0.666200\n",
      "Epoch 80, CIFAR-10 Batch 2:  Loss:   0.4522   Validation Accuracy: 0.669800\n",
      "Epoch 80, CIFAR-10 Batch 3:  Loss:   0.3932   Validation Accuracy: 0.666000\n",
      "Epoch 80, CIFAR-10 Batch 4:  Loss:   0.4266   Validation Accuracy: 0.669000\n",
      "Epoch 80, CIFAR-10 Batch 5:  Loss:   0.4351   Validation Accuracy: 0.669400\n",
      "Epoch 81, CIFAR-10 Batch 1:  Loss:   0.4699   Validation Accuracy: 0.670000\n",
      "Epoch 81, CIFAR-10 Batch 2:  Loss:   0.4494   Validation Accuracy: 0.663400\n",
      "Epoch 81, CIFAR-10 Batch 3:  Loss:   0.4122   Validation Accuracy: 0.665600\n",
      "Epoch 81, CIFAR-10 Batch 4:  Loss:   0.4149   Validation Accuracy: 0.670800\n",
      "Epoch 81, CIFAR-10 Batch 5:  Loss:   0.4326   Validation Accuracy: 0.668800\n",
      "Epoch 82, CIFAR-10 Batch 1:  Loss:   0.4931   Validation Accuracy: 0.665200\n",
      "Epoch 82, CIFAR-10 Batch 2:  Loss:   0.4355   Validation Accuracy: 0.668000\n",
      "Epoch 82, CIFAR-10 Batch 3:  Loss:   0.3981   Validation Accuracy: 0.661600\n",
      "Epoch 82, CIFAR-10 Batch 4:  Loss:   0.4311   Validation Accuracy: 0.663400\n",
      "Epoch 82, CIFAR-10 Batch 5:  Loss:   0.4520   Validation Accuracy: 0.659000\n",
      "Epoch 83, CIFAR-10 Batch 1:  Loss:   0.4897   Validation Accuracy: 0.661200\n",
      "Epoch 83, CIFAR-10 Batch 2:  Loss:   0.4682   Validation Accuracy: 0.654800\n",
      "Epoch 83, CIFAR-10 Batch 3:  Loss:   0.4081   Validation Accuracy: 0.660200\n",
      "Epoch 83, CIFAR-10 Batch 4:  Loss:   0.4051   Validation Accuracy: 0.667800\n",
      "Epoch 83, CIFAR-10 Batch 5:  Loss:   0.4336   Validation Accuracy: 0.668800\n",
      "Epoch 84, CIFAR-10 Batch 1:  Loss:   0.4729   Validation Accuracy: 0.669200\n",
      "Epoch 84, CIFAR-10 Batch 2:  Loss:   0.4364   Validation Accuracy: 0.660000\n",
      "Epoch 84, CIFAR-10 Batch 3:  Loss:   0.3859   Validation Accuracy: 0.661000\n",
      "Epoch 84, CIFAR-10 Batch 4:  Loss:   0.4141   Validation Accuracy: 0.667600\n",
      "Epoch 84, CIFAR-10 Batch 5:  Loss:   0.4408   Validation Accuracy: 0.662400\n",
      "Epoch 85, CIFAR-10 Batch 1:  Loss:   0.4526   Validation Accuracy: 0.659800\n",
      "Epoch 85, CIFAR-10 Batch 2:  Loss:   0.4449   Validation Accuracy: 0.663200\n",
      "Epoch 85, CIFAR-10 Batch 3:  Loss:   0.3942   Validation Accuracy: 0.663400\n",
      "Epoch 85, CIFAR-10 Batch 4:  Loss:   0.3966   Validation Accuracy: 0.666000\n",
      "Epoch 85, CIFAR-10 Batch 5:  Loss:   0.4384   Validation Accuracy: 0.666000\n",
      "Epoch 86, CIFAR-10 Batch 1:  Loss:   0.4686   Validation Accuracy: 0.658600\n",
      "Epoch 86, CIFAR-10 Batch 2:  Loss:   0.4353   Validation Accuracy: 0.656600\n",
      "Epoch 86, CIFAR-10 Batch 3:  Loss:   0.3969   Validation Accuracy: 0.657200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 86, CIFAR-10 Batch 4:  Loss:   0.4027   Validation Accuracy: 0.666400\n",
      "Epoch 86, CIFAR-10 Batch 5:  Loss:   0.4497   Validation Accuracy: 0.661200\n",
      "Epoch 87, CIFAR-10 Batch 1:  Loss:   0.4584   Validation Accuracy: 0.667200\n",
      "Epoch 87, CIFAR-10 Batch 2:  Loss:   0.4332   Validation Accuracy: 0.664000\n",
      "Epoch 87, CIFAR-10 Batch 3:  Loss:   0.3807   Validation Accuracy: 0.668200\n",
      "Epoch 87, CIFAR-10 Batch 4:  Loss:   0.4077   Validation Accuracy: 0.672400\n",
      "Epoch 87, CIFAR-10 Batch 5:  Loss:   0.4232   Validation Accuracy: 0.661600\n",
      "Epoch 88, CIFAR-10 Batch 1:  Loss:   0.4668   Validation Accuracy: 0.663800\n",
      "Epoch 88, CIFAR-10 Batch 2:  Loss:   0.4321   Validation Accuracy: 0.655600\n",
      "Epoch 88, CIFAR-10 Batch 3:  Loss:   0.3712   Validation Accuracy: 0.666800\n",
      "Epoch 88, CIFAR-10 Batch 4:  Loss:   0.3980   Validation Accuracy: 0.667400\n",
      "Epoch 88, CIFAR-10 Batch 5:  Loss:   0.4207   Validation Accuracy: 0.665000\n",
      "Epoch 89, CIFAR-10 Batch 1:  Loss:   0.4701   Validation Accuracy: 0.655800\n",
      "Epoch 89, CIFAR-10 Batch 2:  Loss:   0.4237   Validation Accuracy: 0.661400\n",
      "Epoch 89, CIFAR-10 Batch 3:  Loss:   0.3903   Validation Accuracy: 0.667000\n",
      "Epoch 89, CIFAR-10 Batch 4:  Loss:   0.4193   Validation Accuracy: 0.664200\n",
      "Epoch 89, CIFAR-10 Batch 5:  Loss:   0.4284   Validation Accuracy: 0.662200\n",
      "Epoch 90, CIFAR-10 Batch 1:  Loss:   0.5000   Validation Accuracy: 0.655600\n",
      "Epoch 90, CIFAR-10 Batch 2:  Loss:   0.4198   Validation Accuracy: 0.659200\n",
      "Epoch 90, CIFAR-10 Batch 3:  Loss:   0.3984   Validation Accuracy: 0.661400\n",
      "Epoch 90, CIFAR-10 Batch 4:  Loss:   0.3885   Validation Accuracy: 0.673000\n",
      "Epoch 90, CIFAR-10 Batch 5:  Loss:   0.3987   Validation Accuracy: 0.666000\n",
      "Epoch 91, CIFAR-10 Batch 1:  Loss:   0.4529   Validation Accuracy: 0.663200\n",
      "Epoch 91, CIFAR-10 Batch 2:  Loss:   0.4028   Validation Accuracy: 0.656800\n",
      "Epoch 91, CIFAR-10 Batch 3:  Loss:   0.3826   Validation Accuracy: 0.661600\n",
      "Epoch 91, CIFAR-10 Batch 4:  Loss:   0.3849   Validation Accuracy: 0.669000\n",
      "Epoch 91, CIFAR-10 Batch 5:  Loss:   0.4163   Validation Accuracy: 0.669000\n",
      "Epoch 92, CIFAR-10 Batch 1:  Loss:   0.4516   Validation Accuracy: 0.660800\n",
      "Epoch 92, CIFAR-10 Batch 2:  Loss:   0.3922   Validation Accuracy: 0.663600\n",
      "Epoch 92, CIFAR-10 Batch 3:  Loss:   0.3917   Validation Accuracy: 0.671600\n",
      "Epoch 92, CIFAR-10 Batch 4:  Loss:   0.3855   Validation Accuracy: 0.667600\n",
      "Epoch 92, CIFAR-10 Batch 5:  Loss:   0.4163   Validation Accuracy: 0.666200\n",
      "Epoch 93, CIFAR-10 Batch 1:  Loss:   0.4483   Validation Accuracy: 0.661800\n",
      "Epoch 93, CIFAR-10 Batch 2:  Loss:   0.3961   Validation Accuracy: 0.661200\n",
      "Epoch 93, CIFAR-10 Batch 3:  Loss:   0.3566   Validation Accuracy: 0.670800\n",
      "Epoch 93, CIFAR-10 Batch 4:  Loss:   0.4019   Validation Accuracy: 0.672600\n",
      "Epoch 93, CIFAR-10 Batch 5:  Loss:   0.4067   Validation Accuracy: 0.663400\n",
      "Epoch 94, CIFAR-10 Batch 1:  Loss:   0.4379   Validation Accuracy: 0.659600\n",
      "Epoch 94, CIFAR-10 Batch 2:  Loss:   0.3892   Validation Accuracy: 0.663400\n",
      "Epoch 94, CIFAR-10 Batch 3:  Loss:   0.3755   Validation Accuracy: 0.668800\n",
      "Epoch 94, CIFAR-10 Batch 4:  Loss:   0.3743   Validation Accuracy: 0.670600\n",
      "Epoch 94, CIFAR-10 Batch 5:  Loss:   0.4011   Validation Accuracy: 0.661200\n",
      "Epoch 95, CIFAR-10 Batch 1:  Loss:   0.4633   Validation Accuracy: 0.661200\n",
      "Epoch 95, CIFAR-10 Batch 2:  Loss:   0.4021   Validation Accuracy: 0.656800\n",
      "Epoch 95, CIFAR-10 Batch 3:  Loss:   0.3744   Validation Accuracy: 0.666600\n",
      "Epoch 95, CIFAR-10 Batch 4:  Loss:   0.3961   Validation Accuracy: 0.666400\n",
      "Epoch 95, CIFAR-10 Batch 5:  Loss:   0.4046   Validation Accuracy: 0.662000\n",
      "Epoch 96, CIFAR-10 Batch 1:  Loss:   0.4337   Validation Accuracy: 0.668800\n",
      "Epoch 96, CIFAR-10 Batch 2:  Loss:   0.3867   Validation Accuracy: 0.665000\n",
      "Epoch 96, CIFAR-10 Batch 3:  Loss:   0.3576   Validation Accuracy: 0.665800\n",
      "Epoch 96, CIFAR-10 Batch 4:  Loss:   0.3790   Validation Accuracy: 0.670800\n",
      "Epoch 96, CIFAR-10 Batch 5:  Loss:   0.4074   Validation Accuracy: 0.662600\n",
      "Epoch 97, CIFAR-10 Batch 1:  Loss:   0.4447   Validation Accuracy: 0.666200\n",
      "Epoch 97, CIFAR-10 Batch 2:  Loss:   0.3854   Validation Accuracy: 0.661600\n",
      "Epoch 97, CIFAR-10 Batch 3:  Loss:   0.3604   Validation Accuracy: 0.666400\n",
      "Epoch 97, CIFAR-10 Batch 4:  Loss:   0.3916   Validation Accuracy: 0.668800\n",
      "Epoch 97, CIFAR-10 Batch 5:  Loss:   0.4107   Validation Accuracy: 0.659400\n",
      "Epoch 98, CIFAR-10 Batch 1:  Loss:   0.4306   Validation Accuracy: 0.668800\n",
      "Epoch 98, CIFAR-10 Batch 2:  Loss:   0.3827   Validation Accuracy: 0.665400\n",
      "Epoch 98, CIFAR-10 Batch 3:  Loss:   0.3806   Validation Accuracy: 0.664000\n",
      "Epoch 98, CIFAR-10 Batch 4:  Loss:   0.3790   Validation Accuracy: 0.672400\n",
      "Epoch 98, CIFAR-10 Batch 5:  Loss:   0.3929   Validation Accuracy: 0.668000\n",
      "Epoch 99, CIFAR-10 Batch 1:  Loss:   0.4372   Validation Accuracy: 0.665600\n",
      "Epoch 99, CIFAR-10 Batch 2:  Loss:   0.3866   Validation Accuracy: 0.665600\n",
      "Epoch 99, CIFAR-10 Batch 3:  Loss:   0.3522   Validation Accuracy: 0.667800\n",
      "Epoch 99, CIFAR-10 Batch 4:  Loss:   0.3660   Validation Accuracy: 0.669400\n",
      "Epoch 99, CIFAR-10 Batch 5:  Loss:   0.3851   Validation Accuracy: 0.665000\n",
      "Epoch 100, CIFAR-10 Batch 1:  Loss:   0.4205   Validation Accuracy: 0.658800\n",
      "Epoch 100, CIFAR-10 Batch 2:  Loss:   0.3950   Validation Accuracy: 0.659800\n",
      "Epoch 100, CIFAR-10 Batch 3:  Loss:   0.3908   Validation Accuracy: 0.660600\n",
      "Epoch 100, CIFAR-10 Batch 4:  Loss:   0.3633   Validation Accuracy: 0.673000\n",
      "Epoch 100, CIFAR-10 Batch 5:  Loss:   0.3912   Validation Accuracy: 0.665600\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "save_model_path = './image_classification'\n",
    "\n",
    "print('Training...')\n",
    "with tf.Session() as sess:\n",
    "    # Initializing the variables\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    # Training cycle\n",
    "    for epoch in range(epochs):\n",
    "        # Loop over all batches\n",
    "        n_batches = 5\n",
    "        for batch_i in range(1, n_batches + 1):\n",
    "            for batch_features, batch_labels in helper.load_preprocess_training_batch(batch_i, batch_size):\n",
    "                train_neural_network(sess, optimizer, keep_probability, batch_features, batch_labels)\n",
    "            print('Epoch {:>2}, CIFAR-10 Batch {}:  '.format(epoch + 1, batch_i), end='')\n",
    "            print_stats(sess, batch_features, batch_labels, cost, accuracy)\n",
    "            \n",
    "    # Save Model\n",
    "    saver = tf.train.Saver()\n",
    "    save_path = saver.save(sess, save_model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Checkpoint\n",
    "The model has been saved to disk.\n",
    "## Test Model\n",
    "Test your model against the test dataset.  This will be your final accuracy. You should have an accuracy greater than 50%. If you don't, keep tweaking the model architecture and parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./image_classification\n",
      "Testing Accuracy: 0.6741153478622437\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1620008e908>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 319,
       "width": 355
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "import tensorflow as tf\n",
    "import pickle\n",
    "import helper\n",
    "import random\n",
    "\n",
    "# Set batch size if not already set\n",
    "try:\n",
    "    if batch_size:\n",
    "        pass\n",
    "except NameError:\n",
    "    batch_size = 64\n",
    "\n",
    "save_model_path = './image_classification'\n",
    "n_samples = 4\n",
    "top_n_predictions = 3\n",
    "\n",
    "def test_model():\n",
    "    \"\"\"\n",
    "    Test the saved model against the test dataset\n",
    "    \"\"\"\n",
    "\n",
    "    test_features, test_labels = pickle.load(open('preprocess_test.p', mode='rb'))\n",
    "    loaded_graph = tf.Graph()\n",
    "\n",
    "    with tf.Session(graph=loaded_graph) as sess:\n",
    "        # Load model\n",
    "        loader = tf.train.import_meta_graph(save_model_path + '.meta')\n",
    "        loader.restore(sess, save_model_path)\n",
    "\n",
    "        # Get Tensors from loaded model\n",
    "        loaded_x = loaded_graph.get_tensor_by_name('x:0')\n",
    "        loaded_y = loaded_graph.get_tensor_by_name('y:0')\n",
    "        loaded_keep_prob = loaded_graph.get_tensor_by_name('keep_prob:0')\n",
    "        loaded_logits = loaded_graph.get_tensor_by_name('logits:0')\n",
    "        loaded_acc = loaded_graph.get_tensor_by_name('accuracy:0')\n",
    "        \n",
    "        # Get accuracy in batches for memory limitations\n",
    "        test_batch_acc_total = 0\n",
    "        test_batch_count = 0\n",
    "        \n",
    "        for test_feature_batch, test_label_batch in helper.batch_features_labels(test_features, test_labels, batch_size):\n",
    "            test_batch_acc_total += sess.run(\n",
    "                loaded_acc,\n",
    "                feed_dict={loaded_x: test_feature_batch, loaded_y: test_label_batch, loaded_keep_prob: 1.0})\n",
    "            test_batch_count += 1\n",
    "\n",
    "        print('Testing Accuracy: {}\\n'.format(test_batch_acc_total/test_batch_count))\n",
    "\n",
    "        # Print Random Samples\n",
    "        random_test_features, random_test_labels = tuple(zip(*random.sample(list(zip(test_features, test_labels)), n_samples)))\n",
    "        random_test_predictions = sess.run(\n",
    "            tf.nn.top_k(tf.nn.softmax(loaded_logits), top_n_predictions),\n",
    "            feed_dict={loaded_x: random_test_features, loaded_y: random_test_labels, loaded_keep_prob: 1.0})\n",
    "        helper.display_image_predictions(random_test_features, random_test_labels, random_test_predictions)\n",
    "\n",
    "\n",
    "test_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Why 50-80% Accuracy?\n",
    "You might be wondering why you can't get an accuracy any higher. First things first, 50% isn't bad for a simple CNN.  Pure guessing would get you 10% accuracy. However, you might notice people are getting scores [well above 80%](http://rodrigob.github.io/are_we_there_yet/build/classification_datasets_results.html#43494641522d3130).  That's because we haven't taught you all there is to know about neural networks. We still need to cover a few more techniques.\n",
    "## Submitting This Project\n",
    "When submitting this project, make sure to run all the cells before saving the notebook.  Save the notebook file as \"dlnd_image_classification.ipynb\" and save it as a HTML file under \"File\" -> \"Download as\".  Include the \"helper.py\" and \"problem_unittests.py\" files in your submission."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
